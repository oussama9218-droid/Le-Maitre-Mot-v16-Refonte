from fastapi import FastAPI, APIRouter, HTTPException, Response, Depends, BackgroundTasks, Request, Form, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field, EmailStr
from typing import List, Optional, Dict
import uuid
from datetime import datetime, timezone, timedelta
from emergentintegrations.llm.chat import LlmChat, UserMessage
from emergentintegrations.payments.stripe.checkout import StripeCheckout, CheckoutSessionResponse, CheckoutStatusResponse, CheckoutSessionRequest
import json
import re
import tempfile
import weasyprint
from jinja2 import Template
from latex_to_svg import latex_renderer
from geometry_renderer import geometry_renderer
from render_schema import schema_renderer
import requests
import latex2mathml.converter
from logger import get_logger, log_execution_time, log_ai_generation, log_schema_processing, log_user_context, log_quota_check
from curriculum_data import (
    CURRICULUM_DATA, 
    get_available_subjects, 
    get_levels_for_subject, 
    get_all_chapters_for_level,
    build_prompt_context,
    process_math_content_for_pdf
)
from curriculum_complete import (
    CURRICULUM_DATA_COMPLETE, 
    CURRICULUM_STATUS,
    get_all_subjects_with_status,
    get_active_subjects,
    get_subject_by_name,
    is_subject_active,
    get_subjects_by_status,
    get_curriculum_stats,
    log_feature_flag_access,
    process_math_content_for_pdf
)
from document_search import search_educational_document

ROOT_DIR = Path(__file__).parent
TEMPLATES_DIR = ROOT_DIR / 'templates'
load_dotenv(ROOT_DIR / '.env')

# Template loading function
def load_template(template_name: str) -> str:
    """Load HTML template from templates directory"""
    template_path = TEMPLATES_DIR / f"{template_name}.html"
    if not template_path.exists():
        raise FileNotFoundError(f"Template {template_name}.html not found in {TEMPLATES_DIR}")
    
    with open(template_path, 'r', encoding='utf-8') as f:
        return f.read()

# Icon mapping for exercises - Professional cascading logic
EXERCISE_ICON_MAPPING = {
    # Priority 1: By exercise type (most robust)
    "geometry": "triangle-ruler",
    "algebra": "calculator",
    "statistics": "bar-chart",
    "probability": "dice-6",
    "text": "file-text",
    
    # NOUVEAU - Physique-Chimie
    "experimental": "atom",
    "physics": "zap",
    "chemistry": "flask",
    "energy": "battery",
    "waves": "radio",
    
    # NOUVEAU - G√©ographie
    "cartographic": "map",
    "geographic": "compass",
    "demographic": "users",
    "urban": "building-2",
    "analysis": "leaf",
    "biology": "dna",
    "geology": "mountain",
    "ecology": "globe",
    "health": "heart",
    
    # Priority 2: By chapter (fallback)
    "Th√©or√®me de Pythagore": "triangle-ruler",
    "Th√©or√®me de Thal√®s": "triangle-ruler", 
    "Trigonom√©trie": "triangle-ruler",
    "G√©om√©trie": "triangle-ruler",
    "G√©om√©trie dans l'espace": "cube",
    "G√©om√©trie - Triangles et quadrilat√®res": "triangle-ruler",
    "Fractions": "calculator",
    "√âquations": "calculator",
    "Fonctions": "function-square",
    "Statistiques": "bar-chart",
    "Probabilit√©s": "dice-6",
    "Volumes": "cube",
    
    # Physique-Chimie specific chapters
    "Organisation et transformations de la mati√®re": "flask",
    "Constitution et transformations de la mati√®re": "flask",
    "Mouvements et interactions": "zap", 
    "Mouvement et interactions": "zap",
    "L'√©nergie et ses conversions": "battery",
    "L'√©nergie : conversions et transferts": "battery",
    "Des signaux pour observer et communiquer": "radio",
    "Ondes et signaux": "radio",
    
    # SVT specific chapters
    "La plan√®te Terre, l'environnement et l'action humaine": "globe",
    "Le vivant et son √©volution": "dna",
    "Le corps humain et la sant√©": "heart",
    "La Terre, la vie et l'organisation du vivant": "leaf",
    "Les enjeux contemporains de la plan√®te": "mountain",
    "Corps humain et sant√©": "heart",
    
    # G√©ographie specific chapters
    "D√©couvrir le(s) lieu(x) o√π j'habite": "map",
    "Se loger, travailler, se cultiver, avoir des loisirs": "building-2",
    "Satisfaire les besoins en √©nergie, en eau": "compass",
    "Se d√©placer - Moyens de transport": "map",
    "Communiquer d'un bout √† l'autre du monde": "globe",
    "Mieux habiter - La ville de demain": "building-2",
    "Mieux habiter - Les espaces ruraux": "mountain",
    "L'urbanisation du monde": "building-2",
    "Les mobilit√©s humaines transnationales": "users",
    "Des espaces transform√©s par la mondialisation": "globe",
    "Soci√©t√©s et environnements : des √©quilibres fragiles": "compass",
    "Territoires, populations et d√©veloppement": "users",
    "Des mobilit√©s g√©n√©ralis√©es": "map",
    "L'Afrique australe : un espace en profonde mutation": "compass",
    "Physique-Chimie": "atom",
    "SVT": "leaf",
    "G√©ographie": "map",
    
    # Priority 3: Default fallback
    "default": "book-open"
}

def enrich_exercise_with_icon(exercise_data: dict, chapitre: str, matiere: str = None) -> dict:
    """
    Professional cascading icon enrichment logic extended for Physique-Chimie and SVT:
    1. Priority: Use matiere-specific logic first
    2. Fallback: Use type from AI if provided and valid
    3. Detection: Use chapter-based mapping  
    4. Content: Analyze content for type hints
    5. Default: Use generic icon
    """
    logger = get_logger()
    
    # Priority 1: Matiere-specific logic FIRST
    if matiere == "Physique-Chimie":
        logger.info(f"üß™ Enriching Physique-Chimie exercise for chapter: {chapitre}")
        if any(word in chapitre.lower() for word in ["mati√®re", "transformation", "constitution", "chimie"]):
            exercise_data["type"] = "chemistry"
            exercise_data["icone"] = "flask"
        elif any(word in chapitre.lower() for word in ["√©nergie", "conversion", "transfert"]):
            exercise_data["type"] = "energy"  
            exercise_data["icone"] = "battery"
        elif any(word in chapitre.lower() for word in ["mouvement", "interaction", "force"]):
            exercise_data["type"] = "physics"
            exercise_data["icone"] = "zap"
        elif any(word in chapitre.lower() for word in ["signal", "onde", "communiquer"]):
            exercise_data["type"] = "waves"
            exercise_data["icone"] = "radio"
        else:
            exercise_data["type"] = "experimental"
            exercise_data["icone"] = "atom"
        logger.info(f"üß™ Assigned type: {exercise_data['type']}, icon: {exercise_data['icone']}")
        return exercise_data
            
    elif matiere == "SVT":
        logger.info(f"üå± Enriching SVT exercise for chapter: {chapitre}")
        if any(word in chapitre.lower() for word in ["vivant", "√©volution", "g√©n√©tique", "vie"]):
            exercise_data["type"] = "biology"
            exercise_data["icone"] = "dna"
        elif any(word in chapitre.lower() for word in ["terre", "plan√®te", "g√©ologique", "enjeux"]):
            exercise_data["type"] = "geology"
            exercise_data["icone"] = "mountain"
        elif any(word in chapitre.lower() for word in ["environnement", "√©cosyst√®me", "action humaine"]):
            exercise_data["type"] = "ecology"
            exercise_data["icone"] = "globe"
        elif any(word in chapitre.lower() for word in ["corps", "sant√©", "humain"]):
            exercise_data["type"] = "health"
            exercise_data["icone"] = "heart"
        else:
            exercise_data["type"] = "analysis"
            exercise_data["icone"] = "leaf"
        logger.info(f"üå± Assigned type: {exercise_data['type']}, icon: {exercise_data['icone']}")
        return exercise_data
    
    elif matiere == "G√©ographie":
        logger.info(f"üó∫Ô∏è Enriching G√©ographie exercise for chapter: {chapitre}")
        if any(word in chapitre.lower() for word in ["ville", "urbain", "habitat", "loger", "b√¢ti"]):
            exercise_data["type"] = "urban"
            exercise_data["icone"] = "building-2"
        elif any(word in chapitre.lower() for word in ["population", "d√©mographi", "mobilit√©", "humain"]):
            exercise_data["type"] = "demographic"
            exercise_data["icone"] = "users"
        elif any(word in chapitre.lower() for word in ["monde", "mondial", "mondialisation", "plan√®te"]):
            exercise_data["type"] = "geographic"
            exercise_data["icone"] = "globe"
        elif any(word in chapitre.lower() for word in ["territoire", "espace", "lieu", "r√©gion"]):
            exercise_data["type"] = "geographic"
            exercise_data["icone"] = "compass"
        else:
            exercise_data["type"] = "cartographic"
            exercise_data["icone"] = "map"
        logger.info(f"üó∫Ô∏è Assigned type: {exercise_data['type']}, icon: {exercise_data['icone']}")
        return exercise_data
    
    # Priority 2: Use type from AI if provided and valid (existing logic for Math√©matiques)
    ai_type = exercise_data.get("type", "").lower()
    if ai_type in EXERCISE_ICON_MAPPING:
        exercise_data["icone"] = EXERCISE_ICON_MAPPING[ai_type]
        exercise_data["type"] = ai_type  # Ensure type is set
        return exercise_data
    
    # Priority 3: Use chapter-based mapping
    if chapitre in EXERCISE_ICON_MAPPING:
        exercise_data["icone"] = EXERCISE_ICON_MAPPING[chapitre]
        # Infer type from chapter for Math√©matiques
        if matiere == "Math√©matiques":
            if any(geo_word in chapitre.lower() for geo_word in ["g√©om√©trie", "pythagore", "thal√®s", "trigonom√©trie", "triangle", "volume"]):
                exercise_data["type"] = "geometry"
            elif any(alg_word in chapitre.lower() for alg_word in ["√©quation", "fonction", "fraction", "alg√®bre", "calcul"]):
                exercise_data["type"] = "algebra"
            elif any(stat_word in chapitre.lower() for stat_word in ["statistique", "probabilit√©"]):
                exercise_data["type"] = "statistics"
            else:
                exercise_data["type"] = "text"
        return exercise_data
    
    # Priority 4: Content-based detection (for unknown chapters) - mainly for Math√©matiques
    enonce = exercise_data.get("enonce", "").lower()
    if matiere == "Math√©matiques":
        if any(geo_word in enonce for geo_word in ["triangle", "cercle", "carr√©", "rectangle", "g√©om√©trique", "angle", "c√¥t√©", "volume", "aire"]):
            exercise_data["type"] = "geometry"
            exercise_data["icone"] = "triangle-ruler"
        elif any(alg_word in enonce for alg_word in ["√©quation", "fonction", "fraction", "calcul", "nombre", "r√©soudre", "simplifier"]):
            exercise_data["type"] = "algebra" 
            exercise_data["icone"] = "calculator"
        elif any(stat_word in enonce for stat_word in ["statistique", "moyenne", "graphique", "donn√©es", "probabilit√©", "hasard"]):
            exercise_data["type"] = "statistics"
            exercise_data["icone"] = "bar-chart"
        else:
            # Priority 5: Default fallback
            exercise_data["type"] = "text"
            exercise_data["icone"] = EXERCISE_ICON_MAPPING["default"]
    else:
        # For non-math subjects, use matiere fallback
        fallback_icon = EXERCISE_ICON_MAPPING.get(matiere, EXERCISE_ICON_MAPPING["default"])
        exercise_data["icone"] = fallback_icon
        exercise_data["type"] = "text"
    
    return exercise_data

# Removed duplicate sanitize_ai_response function - using the newer one below

# Professional content processing function
@log_execution_time("process_schema_to_base64")
def process_schema_to_base64(schema: Optional[dict]) -> Optional[str]:
    """
    Process a geometric schema dictionary to Base64 image for web display.
    Returns Base64 string or None if no schema or processing failed.
    """
    logger = get_logger()
    
    if not schema or not isinstance(schema, dict):
        logger.debug("No schema provided or invalid schema format")
        return None
    
    schema_type = schema.get("type", "unknown")
    logger.debug(
        "Starting schema to Base64 conversion",
        module_name="schema",
        func_name="process_schema_to_base64",
        schema_type=schema_type
    )
    
    try:
        # Convert schema to geometry_renderer format
        geometry_schema = {
            "type": "schema_geometrique",
            "figure": schema.get("type", "triangle"),
            "donnees": schema
        }
        
        # Render to Base64 for web display
        base64_image = geometry_renderer.render_geometry_to_base64(geometry_schema)
        
        if base64_image:
            logger.info(
                "Schema successfully rendered to Base64",
                module_name="schema",
                func_name="process_schema_to_base64",
                schema_type=schema_type,
                base64_length=len(base64_image),
                status="success"
            )
            log_schema_processing(schema_type, True)
            return base64_image
        else:
            logger.warning(
                "Schema rendering failed",
                module_name="schema",
                func_name="process_schema_to_base64",
                schema_type=schema_type,
                status="failed"
            )
            log_schema_processing(schema_type, False)
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error processing schema to Base64: {e}")
        return None

def process_exercise_content(content: str) -> str:
    """
    Processes the exercise content to render both LaTeX and geometric schemas.
    This centralizes all content processing logic for consistency.
    """
    if not content or not isinstance(content, str):
        return content if isinstance(content, str) else ""
    
    # 1. Process legacy geometric schemas (for backward compatibility)
    try:
        content = geometry_renderer.process_geometric_schemas_for_web(content)
    except Exception as e:
        logger.error(f"Error processing legacy geometric schemas: {e}")
    
    # 2. Process LaTeX formulas
    try:
        content = latex_renderer.convert_latex_to_svg(content)
    except Exception as e:
        logger.error(f"Error processing LaTeX: {e}")
    
    return content

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Create the main app without a prefix
app = FastAPI()

# Create uploads directory and mount static files
uploads_dir = ROOT_DIR / "uploads"
uploads_dir.mkdir(exist_ok=True)
app.mount("/uploads", StaticFiles(directory=str(uploads_dir)), name="uploads")

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")

# Initialize LLM Chat
emergent_key = os.environ.get('EMERGENT_LLM_KEY')

# Initialize Stripe
stripe_secret_key = os.environ.get('STRIPE_SECRET_KEY')

# Define pricing packages (server-side only for security)
PRICING_PACKAGES = {
    "monthly": {
        "name": "Abonnement Mensuel",
        "amount": 9.99,
        "currency": "eur",
        "duration": "monthly",
        "description": "Acc√®s illimit√© pendant 1 mois"
    },
    "yearly": {
        "name": "Abonnement Annuel", 
        "amount": 99.00,
        "currency": "eur",
        "duration": "yearly",
        "description": "Acc√®s illimit√© pendant 1 an - √âconomisez 16%"
    }
}

# Define template styles available for export
EXPORT_TEMPLATE_STYLES = {
    "classique": {
        "name": "Classique",
        "description": "Style traditionnel √©l√©gant avec typographie serif",
        "preview_image": "/api/template-previews/classique.png",
        "available_for": ["free", "pro"],
        "sujet_template": "sujet_classique",
        "corrige_template": "corrige_classique"
    },
    "moderne": {
        "name": "Moderne",
        "description": "Style contemporain avec couleurs vives et design √©pur√©",
        "preview_image": "/api/template-previews/moderne.png",
        "available_for": ["pro"],
        "sujet_template": "sujet_moderne",
        "corrige_template": "corrige_moderne"
    },
    "eleve": {
        "name": "√âl√®ve",
        "description": "Style color√© et ludique avec couleurs pastel",
        "preview_image": "/api/template-previews/eleve.png",
        "available_for": ["pro"],
        "sujet_template": "sujet_eleve",
        "corrige_template": "corrige_eleve"
    },
    "corrige_detaille": {
        "name": "Corrig√© d√©taill√©",
        "description": "Template sp√©cialis√© pour corrections avec bar√®me et crit√®res",
        "preview_image": "/api/template-previews/corrige_detaille.png",
        "available_for": ["pro"],
        "sujet_template": "sujet_classique",  # Utilise classique pour les sujets
        "corrige_template": "corrige_detaille"
    },
    "minimal": {
        "name": "Minimal",
        "description": "Style ultra-√©pur√©, focus sur le contenu",
        "preview_image": "/api/template-previews/minimal.png",
        "available_for": ["pro"],
        "sujet_template": "sujet_minimal",
        "corrige_template": "corrige_minimal"
    },
    "academique": {
        "name": "Acad√©mique",
        "description": "Style officiel scolaire avec espaces de r√©ponse et bar√®me",
        "preview_image": "/api/template-previews/academique.png",
        "available_for": ["pro"],
        "sujet_template": "sujet_academique",
        "corrige_template": "corrige_academique"
    }
}

# Define Models
class Exercise(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    type: str  # "ouvert", "qcm", "mixte"
    enonce: str
    donnees: Optional[dict] = None
    difficulte: str  # "facile", "moyen", "difficile"
    solution: dict  # {"etapes": [...], "resultat": "..."}
    bareme: List[dict] = []  # [{"etape": "...", "points": 1.0}]
    version: str = "A"
    seed: Optional[int] = None
    # New fields for UI enhancement
    exercise_type: Optional[str] = "text"  # "geometry", "algebra", "statistics", "text"
    icone: Optional[str] = "book-open"  # Icon identifier for frontend
    # NEW: Separate geometric schema field (clean design) 
    geometric_schema: Optional[dict] = None  # Geometric schema data separate from text
    # CRITICAL: Base64 schema image for frontend display
    schema_img: Optional[str] = None  # Base64 PNG image for web display
    # NEW: Geographic document for Geography exercises
    document: Optional[dict] = None  # Educational document metadata for Geography

class Document(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_id: Optional[str] = None  # For Pro users
    guest_id: Optional[str] = None  # For guest users
    matiere: str
    niveau: str
    chapitre: str
    type_doc: str  # "exercices", "controle", "dm"
    difficulte: str
    nb_exercices: int
    exercises: List[Exercise] = []
    export_count: int = 0  # Track exports for quotas
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ProUser(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    email: EmailStr
    nom: Optional[str] = None
    etablissement: Optional[str] = None
    account_type: str = "pro"
    subscription_type: str  # "monthly" or "yearly"
    subscription_expires: datetime
    stripe_customer_id: Optional[str] = None
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    last_login: Optional[datetime] = None

class PaymentTransaction(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    session_id: str
    payment_id: Optional[str] = None
    amount: float
    currency: str
    package_id: str
    email: Optional[str] = None
    user_id: Optional[str] = None
    payment_status: str = "pending"  # pending, paid, failed, expired
    session_status: str = "initiated"  # initiated, complete, expired
    metadata: Optional[Dict] = None
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class LoginSession(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_email: EmailStr
    session_token: str
    device_id: str  # Unique identifier for device/browser
    expires_at: datetime
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    last_used: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class LoginRequest(BaseModel):
    email: EmailStr

class VerifyLoginRequest(BaseModel):
    token: str
    device_id: str

class UserTemplate(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    user_email: EmailStr
    logo_filename: Optional[str] = None
    logo_url: Optional[str] = None
    professor_name: Optional[str] = None
    school_name: Optional[str] = None
    school_year: Optional[str] = None
    footer_text: Optional[str] = None
    template_style: str = "minimaliste"  # minimaliste, classique, moderne
    colors: Optional[Dict] = None
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class GenerateRequest(BaseModel):
    matiere: str
    niveau: str
    chapitre: str
    type_doc: str
    difficulte: str = "moyen"
    nb_exercices: int = 6
    versions: List[str] = ["A"]
    guest_id: Optional[str] = None

class ExportRequest(BaseModel):
    document_id: str
    export_type: str  # "sujet" or "corrige"
    guest_id: Optional[str] = None
    template_style: Optional[str] = "classique"  # Style d'export choisi

class AdvancedPDFOptions(BaseModel):
    page_format: str = "A4"  # A4, A4_compact, US_Letter
    margin_preset: str = "standard"  # standard, compact, generous
    custom_margins: Optional[Dict[str, str]] = None  # Override margin_preset if provided
    show_difficulty: bool = True
    show_creation_date: bool = True
    show_exercise_numbers: bool = True
    show_point_values: bool = True
    include_instructions: bool = True
    page_numbering: str = "bottom_center"  # bottom_center, bottom_right, top_right, none
    exercise_separator: str = "line"  # line, space, box, none
    question_numbering: str = "arabic"  # arabic, roman, letters, none
    color_scheme: str = "professional"  # professional, academic, modern, minimal
    font_scaling: float = 1.0  # 0.8 to 1.2

class EnhancedExportRequest(BaseModel):
    document_id: str
    export_type: str  # "sujet" or "corrige"
    guest_id: Optional[str] = None
    advanced_options: Optional[AdvancedPDFOptions] = None

class CheckoutRequest(BaseModel):
    package_id: str  # "monthly" or "yearly"
    origin_url: str
    email: Optional[str] = None
    nom: Optional[str] = None
    etablissement: Optional[str] = None

class CatalogItem(BaseModel):
    name: str
    levels: Optional[List[str]] = None
    chapters: Optional[List[str]] = None

class AnalyticsRequest(BaseModel):
    date_from: Optional[str] = None  # ISO date string
    date_to: Optional[str] = None
    user_email: Optional[str] = None  # For Pro users to see their own stats

class TemplateSaveRequest(BaseModel):
    professor_name: Optional[str] = None
    school_name: Optional[str] = None
    school_year: Optional[str] = None
    footer_text: Optional[str] = None
    template_style: str = "minimaliste"

# French curriculum data
# CURRICULUM_DATA is now imported from curriculum_data.py

# PDF Templates - Unified WeasyPrint approach
TEMPLATE_STYLES = {
    "minimaliste": {
        "name": "Minimaliste",
        "description": "Design √©pur√© et moderne",
        "header_font": "Helvetica",
        "header_font_size": 14,
        "content_font": "Helvetica",
        "content_font_size": 11,
        "primary_color": "#2c3e50",
        "secondary_color": "#7f8c8d",
        "accent_color": "#3498db",
        "separator_style": "line",
        "logo_max_height": 40
    },
    "classique": {
        "name": "Classique",
        "description": "Style acad√©mique traditionnel",
        "header_font": "Times-Roman",
        "header_font_size": 16,
        "content_font": "Times-Roman", 
        "content_font_size": 12,
        "primary_color": "#1a1a1a",
        "secondary_color": "#4a4a4a",
        "accent_color": "#8b4513",
        "separator_style": "double_line",
        "logo_max_height": 45
    },
    "moderne": {
        "name": "Moderne",
        "description": "Design contemporain et a√©r√©",
        "header_font": "Helvetica-Light",
        "header_font_size": 15,
        "content_font": "Helvetica",
        "content_font_size": 11,
        "primary_color": "#34495e",
        "secondary_color": "#95a5a6",
        "accent_color": "#e74c3c",
        "separator_style": "gradient",
        "logo_max_height": 50
    }
}

# Advanced PDF Layout Options
PDF_LAYOUT_OPTIONS = {
    "page_formats": {
        "A4": {"width": "21cm", "height": "29.7cm"},
        "A4_compact": {"width": "21cm", "height": "29.7cm", "margin": "1.5cm"},
        "US_Letter": {"width": "8.5in", "height": "11in"}
    },
    "margin_presets": {
        "standard": {"top": "2.5cm", "bottom": "2.5cm", "left": "2cm", "right": "2cm"},
        "compact": {"top": "1.5cm", "bottom": "1.5cm", "left": "1.5cm", "right": "1.5cm"},
        "generous": {"top": "3cm", "bottom": "3cm", "left": "2.5cm", "right": "2.5cm"}
    },
    "content_options": {
        "show_difficulty": True,
        "show_creation_date": True,
        "show_exercise_numbers": True,
        "show_point_values": True,
        "include_instructions": True,
        "page_numbering": "bottom_center"  # Options: bottom_center, bottom_right, top_right, none
    },
    "visual_enhancements": {
        "exercise_separator": "line",  # Options: line, space, box, none
        "question_numbering": "arabic",  # Options: arabic, roman, letters, none
        "color_scheme": "professional",  # Options: professional, academic, modern, minimal
        "font_scaling": 1.0  # Multiplier for font sizes (0.8 to 1.2)
    }
}

# Templates are now loaded from external files
#ouss

'''"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        @page {
            size: A4;
            margin: 2cm;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            font-size: 12pt;
            line-height: 1.6;
            color: #2c3e50;
            background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            margin: 0;
            padding: 0;
        }
        
        .page-container {
            background: white;
            padding: 30px;
            margin: 20px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            min-height: calc(100vh - 40px);
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding: 25px;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white;
            border-radius: 15px;
            box-shadow: 0 5px 15px rgba(17, 153, 142, 0.3);
        }
        
        .title {
            font-size: 24pt;
            font-weight: bold;
            margin-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .subtitle {
            font-size: 16pt;
            margin-bottom: 8px;
            opacity: 0.9;
        }
        
        .document-info {
            font-size: 12pt;
            margin-top: 15px;
            padding: 10px;
            background: rgba(255,255,255,0.2);
            border-radius: 8px;
        }
        
        .decoration {
            text-align: center;
            font-size: 20pt;
            color: #27ae60;
            margin: 20px 0;
        }
        
        .solution {
            margin: 25px 0;
            page-break-inside: avoid;
            border-left: 4px solid #27ae60;
            background: #f8f9fa;
            border-radius: 0 10px 10px 0;
            padding: 20px;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }
        
        .solution-header {
            background: linear-gradient(90deg, #27ae60, #229954);
            color: white;
            padding: 12px 20px;
            margin: -20px -20px 20px -20px;
            border-radius: 10px 10px 0 0;
            font-size: 16pt;
            font-weight: bold;
        }
        
        .solution-steps {
            background: #e8f5e8;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            border-left: 4px solid #27ae60;
        }
        
        .solution-steps h4 {
            color: #27ae60;
            margin: 0 0 10px 0;
            font-size: 14pt;
        }
        
        .solution-steps ol {
            margin: 0;
            padding-left: 20px;
        }
        
        .solution-steps li {
            margin: 8px 0;
            font-size: 13pt;
            line-height: 1.5;
        }
        
        .final-result {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            font-weight: bold;
            text-align: center;
            font-size: 14pt;
            box-shadow: 0 5px 15px rgba(240, 147, 251, 0.3);
        }
        
        .final-result::before {
            content: "üéØ ";
            font-size: 16pt;
        }
        
        .method-tip {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 8px;
            padding: 12px;
            margin: 15px 0;
            font-style: italic;
            color: #856404;
        }
        
        .method-tip::before {
            content: "üí° Astuce : ";
            font-weight: bold;
            color: #f39c12;
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            border-top: 2px solid #ecf0f1;
            color: #7f8c8d;
            font-size: 11pt;
        }
        
        .success-badge {
            display: inline-block;
            background: #27ae60;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 12pt;
            margin: 10px 5px;
        }
    </style>
</head>
<body>
    <div class="page-container">
        <div class="header">
            <div class="title">{{ document.type_doc.title() }} - Corrig√© ‚úÖ</div>
            <div class="subtitle">{{ document.matiere }} - {{ document.niveau }}</div>
            <div class="subtitle">üìö {{ document.chapitre }}</div>
            <div class="document-info">
                üéØ Difficult√©: {{ document.difficulte.title() }} | 
                üìù {{ document.nb_exercices }} exercices | 
                üìÖ {{ date_creation }}
            </div>
        </div>
        
        <div class="decoration">üåü Solutions d√©taill√©es üåü</div>
        
        <div class="content">
            {% for exercice in document.exercises %}
                <div class="solution">
                    <div class="solution-header">
                        ‚úÖ Exercice {{ loop.index }} - Corrig√©
                    </div>
                    
                    {% if exercice.solution.etapes %}
                        <div class="solution-steps">
                            <h4>üìã M√©thode √©tape par √©tape :</h4>
                            <ol>
                                {% for etape in exercice.solution.etapes %}
                                    <li>{{ etape }}</li>
                                {% endfor %}
                            </ol>
                        </div>
                        
                        <div class="method-tip">
                            Prends ton temps pour comprendre chaque √©tape avant de passer √† la suivante !
                        </div>
                    {% endif %}
                    
                    {% if exercice.solution.resultat %}
                        <div class="final-result">
                            R√©sultat final : {{ exercice.solution.resultat }}
                        </div>
                    {% endif %}
                </div>
            {% endfor %}
        </div>
        
        <div class="success-badge">‚ú® Bravo !</div>
        <div class="success-badge">üéì Bien jou√© !</div>
        <div class="success-badge">üí™ Continue !</div>
        
        <div class="footer">
            üåü Le Ma√Ætre Mot - G√©n√©rateur de documents p√©dagogiques üåü<br>
            <small>Utilise ces corrections pour progresser !</small>
        </div>
    </div>
</body>
</html>
"""
'''
#ouss

# Pro Templates - Ultra Professional Design

@log_execution_time("check_guest_quota")
async def check_guest_quota(guest_id: str):
    """Check if guest user can export (3 exports max)"""
    logger = get_logger()
    logger.debug(
        "Starting guest quota check",
        module_name="quota",
        func_name="check_guest_quota",
        user_type="guest",
        guest_id=guest_id[:8] + "..." if guest_id and len(guest_id) > 8 else guest_id
    )
    
    try:
        thirty_days_ago = datetime.now(timezone.utc) - timedelta(days=30)
        export_count = await db.exports.count_documents({
            "guest_id": guest_id,
            "created_at": {"$gte": thirty_days_ago}
        })
        
        remaining = max(0, 3 - export_count)
        
        # Log quota check result
        log_quota_check("guest", export_count, 3, guest_id=guest_id[:8] + "..." if guest_id and len(guest_id) > 8 else guest_id)
        
        logger.info(
            "Guest quota check completed",
            module_name="quota",
            func_name="check_guest_quota",
            user_type="guest",
            exports_used=export_count,
            exports_remaining=remaining,
            quota_exceeded=remaining == 0
        )
        
        return {
            "exports_used": export_count,
            "exports_remaining": remaining,
            "max_exports": 3,
            "quota_exceeded": remaining == 0
        }
        
    except Exception as e:
        logger.error(f"Error checking guest quota: {e}")
        return {
            "exports_used": 0,
            "exports_remaining": 3,
            "max_exports": 3,
            "quota_exceeded": False
        }

async def check_user_pro_status(email: str):
    """Check if user has active Pro subscription"""
    try:
        user = await db.pro_users.find_one({"email": email})
        if user and user.get("subscription_expires"):
            expires = user["subscription_expires"]
            if isinstance(expires, str):
                expires = datetime.fromisoformat(expires).replace(tzinfo=timezone.utc)
            elif isinstance(expires, datetime) and expires.tzinfo is None:
                expires = expires.replace(tzinfo=timezone.utc)
            
            now = datetime.now(timezone.utc)
            logger.info(f"Checking Pro status for {email}: expires={expires}, now={now}")
            
            if expires > now:
                logger.info(f"User {email} is Pro (expires: {expires})")
                return True, user
            else:
                logger.info(f"User {email} Pro subscription expired")
        
        return False, None
        
    except Exception as e:
        logger.error(f"Error checking pro status: {e}")
        return False, None

async def require_pro_user(request: Request):
    """Middleware to require Pro user authentication"""
    session_token = request.headers.get("X-Session-Token")
    
    if not session_token:
        raise HTTPException(
            status_code=401, 
            detail="Authentification requise pour les fonctionnalit√©s Pro"
        )
    
    email = await validate_session_token(session_token)
    if not email:
        raise HTTPException(
            status_code=401, 
            detail="Session invalide ou expir√©e"
        )
    
    is_pro, user = await check_user_pro_status(email)
    if not is_pro:
        raise HTTPException(
            status_code=403, 
            detail="Abonnement Pro requis pour cette fonctionnalit√©"
        )
    
    return email

# ReportLab-dependent functions commented out due to import removal
# These functions were using ReportLab for PDF generation with personalized templates

# class PersonalizedDocTemplate(BaseDocTemplate):
#     """Custom document template with personalized headers and footers"""
#     [COMMENTED OUT - ReportLab dependency removed]

# def create_personalized_styles(template_config):
#     """Create ReportLab styles based on template configuration"""
#     [COMMENTED OUT - ReportLab dependency removed]

# async def create_personalized_pdf(document, template_config, export_type="sujet"):
#     """Create PDF with personalized template using ReportLab Flowables"""
#     [COMMENTED OUT - ReportLab dependency removed]
#     return None

async def send_magic_link_email(email: str, token: str):
    """Send magic link email via Brevo"""
    try:
        brevo_api_key = os.environ.get('BREVO_API_KEY')
        sender_email = os.environ.get('BREVO_SENDER_EMAIL')
        sender_name = os.environ.get('BREVO_SENDER_NAME', 'Le Ma√Ætre Mot')
        
        if not brevo_api_key or not sender_email:
            logger.error("Brevo credentials not configured")
            return False
        
        # Generate magic link URL
        frontend_url = os.environ.get('FRONTEND_URL', 'https://lemaitremot-1.preview.emergentagent.com')
        magic_link = f"{frontend_url}/login/verify?token={token}"
        
        # Email content
        html_content = f"""
        <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
            <div style="background: linear-gradient(135deg, #3b82f6 0%, #6366f1 100%); padding: 2rem; text-align: center; border-radius: 8px 8px 0 0;">
                <h1 style="color: white; margin: 0; font-size: 1.5rem;">Le Ma√Ætre Mot</h1>
                <p style="color: rgba(255,255,255,0.9); margin: 0.5rem 0 0 0;">Connexion √† votre compte Pro</p>
            </div>
            
            <div style="background: white; padding: 2rem; border-radius: 0 0 8px 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
                <h2 style="color: #1f2937; margin-top: 0;">Connexion demand√©e</h2>
                <p style="color: #4b5563; line-height: 1.6;">
                    Vous avez demand√© √† vous connecter √† votre compte Le Ma√Ætre Mot Pro. 
                    Cliquez sur le bouton ci-dessous pour vous connecter automatiquement.
                </p>
                
                <div style="text-align: center; margin: 2rem 0;">
                    <a href="{magic_link}" 
                       style="background: linear-gradient(135deg, #3b82f6 0%, #6366f1 100%); 
                              color: white;
                              text-decoration: none;
                              padding: 1rem 2rem;
                              border-radius: 8px;
                              font-weight: bold;
                              display: inline-block;">
                        üîê Se connecter √† Le Ma√Ætre Mot Pro
                    </a>
                </div>
                
                <div style="background: #f3f4f6; padding: 1rem; border-radius: 6px; margin: 1.5rem 0;">
                    <p style="margin: 0; font-size: 0.875rem; color: #6b7280;">
                        <strong>‚ö†Ô∏è Important :</strong> Ce lien est valide pendant 15 minutes et ne peut √™tre utilis√© qu'une seule fois.
                        Pour des raisons de s√©curit√©, toute autre session active sera automatiquement ferm√©e.
                    </p>
                </div>
                
                <p style="color: #6b7280; font-size: 0.875rem; line-height: 1.4;">
                    Si vous n'avez pas demand√© cette connexion, ignorez cet email. 
                    Votre compte reste s√©curis√©.
                </p>
                
                <div style="border-top: 1px solid #e5e7eb; margin-top: 2rem; padding-top: 1rem;">
                    <p style="color: #9ca3af; font-size: 0.75rem; margin: 0; text-align: center;">
                        Le Ma√Ætre Mot - G√©n√©rateur de documents p√©dagogiques
                    </p>
                </div>
            </div>
        </div>
        """
        
        # Send email using requests (simple approach)
        import requests
        
        headers = {
            'api-key': brevo_api_key,
            'Content-Type': 'application/json'
        }
        
        data = {
            'sender': {
                'name': sender_name,
                'email': sender_email
            },
            'to': [
                {
                    'email': email,
                    'name': email.split('@')[0]
                }
            ],
            'subject': 'üîê Connexion √† Le Ma√Ætre Mot Pro',
            'htmlContent': html_content
        }
        
        response = requests.post(
            'https://api.brevo.com/v3/smtp/email',
            headers=headers,
            json=data,
            timeout=10
        )
        
        if response.status_code == 201:
            logger.info(f"Magic link email sent successfully to {email}")
            return True
        else:
            logger.error(f"Failed to send magic link email: {response.status_code} - {response.text}")
            return False
            
    except Exception as e:
        logger.error(f"Error sending magic link email: {e}")
        return False

async def create_login_session(email: str, device_id: str):
    """Create a new login session and invalidate old ones"""
    try:
        # Generate secure session token
        session_token = str(uuid.uuid4()) + "-" + str(uuid.uuid4())
        expires_at = datetime.now(timezone.utc) + timedelta(hours=24)
        
        # Create new session data
        session = LoginSession(
            user_email=email,
            session_token=session_token,
            device_id=device_id,
            expires_at=expires_at
        )
        
        session_dict = session.dict()
        session_dict['expires_at'] = session_dict['expires_at'].isoformat()
        session_dict['created_at'] = session_dict['created_at'].isoformat()
        session_dict['last_used'] = session_dict['last_used'].isoformat()
        
        # Remove all existing sessions for this user (single device policy)
        delete_result = await db.login_sessions.delete_many({"user_email": email})
        logger.info(f"Deleted {delete_result.deleted_count} existing sessions for {email}")
        
        # Use upsert to handle race conditions - replace existing session atomically
        upsert_result = await db.login_sessions.replace_one(
            {"user_email": email},
            session_dict,
            upsert=True
        )
        logger.info(f"Created new session for {email} on device {device_id}")
        
        if upsert_result.matched_count > 0:
            logger.info(f"Replaced existing session for {email}")
        else:
            logger.info(f"Created new session for {email}")
        
        # Update user's last_login
        await db.pro_users.update_one(
            {"email": email},
            {"$set": {"last_login": datetime.now(timezone.utc)}}
        )
        
        logger.info(f"Login session created successfully for {email} - all previous sessions invalidated")
        return session_token
        
    except Exception as e:
        logger.error(f"Error creating login session: {e}")
        return None

async def validate_session_token(session_token: str):
    """Validate a session token and return user email if valid"""
    try:
        session = await db.login_sessions.find_one({"session_token": session_token})
        
        if not session:
            return None
            
        # Check expiration
        expires_at = session.get('expires_at')
        if isinstance(expires_at, str):
            expires_at = datetime.fromisoformat(expires_at).replace(tzinfo=timezone.utc)
        elif isinstance(expires_at, datetime) and expires_at.tzinfo is None:
            expires_at = expires_at.replace(tzinfo=timezone.utc)
            
        now = datetime.now(timezone.utc)
        
        if expires_at < now:
            # Session expired, clean it up
            await db.login_sessions.delete_one({"session_token": session_token})
            return None
            
        # Update last_used
        await db.login_sessions.update_one(
            {"session_token": session_token},
            {"$set": {"last_used": datetime.now(timezone.utc)}}
        )
        
        return session.get('user_email')
        
    except Exception as e:
        logger.error(f"Error validating session token: {e}")
        return None

def sanitize_schema_ai_response(response: str) -> str:
    """
    Clean AI responses specifically for geometric schema generation.
    More careful handling to preserve geometric data.
    """
    try:
        # Remove leading/trailing whitespace
        response = response.strip()
        
        # Find JSON boundaries
        json_start = response.find('{')
        json_end = response.rfind('}') + 1
        
        if json_start == -1 or json_end == 0:
            logger.warning(f"No JSON found in schema AI response: {response[:200]}...")
            return '{"schema": null}'
        
        json_content = response[json_start:json_end]
        
        # Gentle cleaning for schemas - avoid aggressive replacements
        # Only fix obvious issues
        json_content = json_content.replace('\\n', ' ')     # Replace literal newlines
        json_content = json_content.replace('\\t', ' ')     # Replace literal tabs
        json_content = re.sub(r'\s+', ' ', json_content)    # Normalize whitespace
        
        # Try to parse as-is first
        try:
            parsed = json.loads(json_content)
            return json.dumps(parsed)  # Re-serialize to ensure valid JSON
        except json.JSONDecodeError as e:
            logger.warning(f"Schema JSON needs cleaning: {e}")
            
            # More aggressive cleaning only if needed
            json_content = json_content.replace('\\\\', '\\')
            json_content = re.sub(r'\\[a-zA-Z]', ' ', json_content)  # Remove problematic escapes
            
            try:
                parsed = json.loads(json_content)
                logger.info("Schema JSON recovered after cleaning")
                return json.dumps(parsed)
            except Exception as e2:
                logger.error(f"Schema JSON still invalid: {e2}")
                return '{"schema": null}'
                
    except Exception as e:
        logger.error(f"Error sanitizing schema AI response: {e}")
        return '{"schema": null}'

def sanitize_ai_response(response: str) -> str:
    """
    Clean and validate AI JSON responses to handle common formatting issues.
    Ensures consistent JSON structure for schema processing.
    """
    try:
        # Remove any leading/trailing whitespace and non-JSON text
        response = response.strip()
        
        # Find JSON boundaries
        json_start = response.find('{')
        json_end = response.rfind('}') + 1
        
        if json_start == -1 or json_end == 0:
            logger.warning(f"No JSON found in AI response: {response[:200]}...")
            return '{"schema": null}'
        
        json_content = response[json_start:json_end]
        
        # PHASE 3 FIX: Clean common JSON formatting issues
        # Fix single quotes to double quotes
        json_content = re.sub(r"'([^']*)':", r'"\1":', json_content)  # Fix keys
        json_content = re.sub(r":\s*'([^']*)'", r': "\1"', json_content)  # Fix values
        
        # Fix missing commas (basic pattern)
        json_content = re.sub(r'}\s*{', '}, {', json_content)
        json_content = re.sub(r']\s*"', '], "', json_content)
        
        # Validate JSON syntax
        try:
            parsed = json.loads(json_content)
            
            # Ensure standard "schema" key (handle various formats)
            if "sch√©ma" in parsed:
                parsed["schema"] = parsed.pop("sch√©ma")
            elif "schema_geometrique" in parsed:
                parsed["schema"] = parsed.pop("schema_geometrique")
            
            # PHASE 3 FIX: Validate schema completeness
            if "schema" in parsed and parsed["schema"] is not None:
                schema = parsed["schema"]
                if isinstance(schema, dict):
                    points = schema.get("points", [])
                    labels = schema.get("labels", {})
                    
                    # Check if all points have coordinates
                    missing_coords = [p for p in points if p not in labels]
                    if missing_coords:
                        logger.warning(
                            "Schema has points without coordinates",
                            module_name="sanitize",
                            func_name="sanitize_ai_response",
                            missing_coords=missing_coords,
                            available_coords=list(labels.keys())
                        )
                        # Try to add default coordinates for missing points
                        for i, point in enumerate(missing_coords):
                            labels[point] = f"({i*2},{i*2})"  # Simple fallback
                        schema["labels"] = labels
                        logger.info(f"Added fallback coordinates for points: {missing_coords}")
            
            # Return cleaned JSON
            return json.dumps(parsed)
            
        except json.JSONDecodeError as e:
            logger.error(
                "Invalid JSON syntax in AI response after cleaning",
                module_name="sanitize",
                func_name="sanitize_ai_response",
                error=str(e),
                json_preview=json_content[:200]
            )
            return '{"schema": null}'
            
    except Exception as e:
        logger.error(f"Error sanitizing AI response: {e}")
        return '{"schema": null}'

@log_execution_time("generate_geometry_schema_with_ai")
async def generate_geometry_schema_with_ai(enonce: str) -> str:
    """
    Makes a second AI call to generate a geometry schema based on the exercise text.
    Returns the JSON string of the schema.
    """
    logger = get_logger()
    logger.debug(
        "Starting geometry schema generation",
        module_name="schema",
        func_name="generate_geometry_schema_with_ai",
        enonce_length=len(enonce),
        enonce_preview=enonce[:100]
    )
    
    try:
        # Create LLM chat instance with faster model
        chat = LlmChat(
            api_key=emergent_key,
            session_id=f"schema_gen_{uuid.uuid4()}",
            system_message="""En tant que moteur de g√©n√©ration de sch√©mas g√©om√©triques PR√âCIS, tu dois cr√©er un sch√©ma qui CORRESPOND EXACTEMENT √† l'√©nonc√© de l'exercice.

**R√àGLE ABSOLUE** : Le sch√©ma DOIT utiliser les M√äMES noms de points et dimensions que l'√©nonc√© !

**Instructions critiques :**
1. LIS attentivement l'√©nonc√© pour identifier TOUS les noms de points mentionn√©s
2. UTILISE exactement ces noms dans le sch√©ma (pas de A,B,C g√©n√©riques !)
3. RESPECTE toutes les dimensions num√©riques mentionn√©es
4. RESPECTE les propri√©t√©s g√©om√©triques (angles droits, etc.)

**Exemples de correspondance correcte :**
- √ânonc√©: "triangle DEF rectangle en E" ‚Üí points: ["D", "E", "F"], angle droit en E
- √ânonc√©: "AB = 5 cm et BC = 12 cm" ‚Üí segments: [["A","B",{"longueur":"5 cm"}], ["B","C",{"longueur":"12 cm"}]]
- √ânonc√©: "triangle GHI" ‚Üí points: ["G", "H", "I"] (pas A, B, C !)

**Format JSON requis :**
{
    "schema": {
        "type": "triangle_rectangle",
        "points": ["points_from_enonce"],
        "segments": [["point1","point2",{"longueur":"value_from_enonce"}]],
        "angles": [["point",{"angle_droit": true}]]
    }
}

**Types support√©s** : triangle, triangle_rectangle, carre, rectangle, cercle
**INTERDIT** : Utiliser A,B,C quand l'√©nonc√© mentionne d'autres lettres !
**OBLIGATOIRE** : Correspondance exacte √©nonc√© ‚Üî sch√©ma"""
        ).with_model("openai", "gpt-4o")
        
        # Create focused prompt for schema generation with STRICT format requirements  
        prompt = f"""
**√âNONC√â DE L'EXERCICE :**
"{enonce}"

Tu dois analyser cet √©nonc√© et g√©n√©rer un sch√©ma g√©om√©trique qui CORRESPOND EXACTEMENT √† l'√©nonc√©.

**R√àGLES CRITIQUES :**
1. UTILISE LES M√äMES NOMS DE POINTS que dans l'√©nonc√© (si l'√©nonc√© dit "triangle DEF", utilise D, E, F)
2. RESPECTE LES DIMENSIONS mentionn√©es dans l'√©nonc√©
3. RESPECTE LES PROPRI√âT√âS g√©om√©triques (angle droit, etc.)

**FORMAT JSON EXACT :**
```json
{{
    "schema": {{
        "type": "triangle_rectangle",
        "points": ["D", "E", "F"],
        "segments": [["D", "E", {{"longueur": "5 cm"}}], ["E", "F", {{"longueur": "12 cm"}}]],
        "angles": [["E", {{"angle_droit": true}}]]
    }}
}}
```

**ANALYSE OBLIGATOIRE :**
1. EXTRAIRE tous les noms de points mentionn√©s (ex: "triangle DEF" ‚Üí points D, E, F)
2. EXTRAIRE toutes les dimensions (ex: "DE = 5 cm" ‚Üí segment DE longueur 5)
3. EXTRAIRE les propri√©t√©s g√©om√©triques (ex: "rectangle en E" ‚Üí angle droit en E)
4. D√âTERMINER le type de figure (triangle, triangle_rectangle, rectangle, etc.)

**G√âN√âRATION OBLIGATOIRE :**
Si l'√©nonc√© mentionne une figure g√©om√©trique (triangle, rectangle, cercle, etc.), tu DOIS g√©n√©rer un sch√©ma complet.

**R√àGLES TECHNIQUES :**
1. TOUJOURS utiliser la cl√© "schema" (sans accent)
2. JAMAIS retourner {{"schema": null}} si l'√©nonc√© contient de la g√©om√©trie
3. Types valides : "triangle", "triangle_rectangle", "rectangle", "carre", "cercle"
4. Format des segments : [["point1", "point2", {{"longueur": "valeur"}}]]
5. Format des angles : [["point", {{"angle_droit": true}}]]

**EXEMPLE CONCRET :**
√ânonc√©: "triangle DEF rectangle en E, DE = 5 cm, EF = 12 cm"
‚Üí DOIT g√©n√©rer: {{"schema": {{"type": "triangle_rectangle", "points": ["D","E","F"], "segments": [["D","E",{{"longueur":"5 cm"}}], ["E","F",{{"longueur":"12 cm"}}]], "angles": [["E",{{"angle_droit":true}}]]}}}}

R√©ponds UNIQUEMENT avec le JSON complet, JAMAIS null pour un √©nonc√© g√©om√©trique.
"""

        user_message = UserMessage(text=prompt)
        
        # Set shorter timeout for faster response
        import asyncio
        response = await asyncio.wait_for(
            chat.send_message(user_message), 
            timeout=15.0  # 15 seconds max for schema generation
        )
        
        # Sanitize and validate the AI response with schema-specific cleaning
        sanitized_response = sanitize_schema_ai_response(response)
        
        # Verify we have a valid schema
        try:
            parsed = json.loads(sanitized_response)
            if parsed.get("schema") is not None:
                schema_type = parsed['schema'].get('type', 'unknown')
                logger.info(
                    "Valid schema generated successfully",
                    module_name="schema",
                    func_name="generate_geometry_schema_with_ai",
                    schema_type=schema_type,
                    status="success"
                )
                log_ai_generation("second_pass_success", True, schema_type=schema_type)
            else:
                logger.debug("No schema needed for this exercise")
                
            return sanitized_response
        except json.JSONDecodeError as e:
            logger.warning(
                "Failed to parse sanitized schema response",
                module_name="schema",
                func_name="generate_geometry_schema_with_ai",
                error=str(e),
                status="parse_error"
            )
            return '{"schema": null}'
        
    except Exception as e:
        logger.error(f"Error in AI geometry generation: {e}")
        return "{}"  # Return empty JSON object on error

@log_execution_time("generate_exercises_with_ai")
async def generate_exercises_with_ai(matiere: str, niveau: str, chapitre: str, type_doc: str, difficulte: str, nb_exercices: int) -> List[Exercise]:
    """Generate exercises using AI"""
    logger = get_logger()
    
    # üéØ RESET DIVERSITY TRACKING for new document generation
    if hasattr(generate_exercises_with_ai, 'used_document_types'):
        generate_exercises_with_ai.used_document_types = []
    
    # Log input parameters
    logger.info(
        "Starting AI exercise generation",
        module_name="generation",
        func_name="generate_exercises_with_ai",
        matiere=matiere,
        niveau=niveau,
        chapitre=chapitre,
        type_doc=type_doc,
        difficulte=difficulte,
        nb_exercices=nb_exercices
    )
    
    # Level-specific guidance
    niveau_guidance = {
        "6e": "Niveau d√©butant - vocabulaire simple, calculs basiques, exemples concrets du quotidien",
        "5e": "Niveau interm√©diaire - introduction de concepts plus abstraits mais restant accessibles", 
        "4e": "Niveau confirm√© - calculs plus complexes, raisonnement math√©matique d√©velopp√©",
        "3e": "Niveau avanc√© - pr√©paration au lyc√©e, concepts abstraits, d√©monstrations"
    }
    
    # PROMPTS IA SP√âCIALIS√âS PAR MATI√àRE by subject
    chapter_examples = {
        # Math√©matiques
        "Volumes": {
            "6e": "Utiliser des objets du quotidien (bo√Ætes, bouteilles), unit√©s simples (cm¬≥, L), calculs avec nombres entiers ou d√©cimaux simples",
            "5e": "Prismes et cylindres, conversions d'unit√©s, calculs avec fractions simples",
            "4e": "Pyramides et c√¥nes, volumes compos√©s, probl√®mes de proportionnalit√©",
            "3e": "Solides de r√©volution, probl√®mes d'optimisation, calculs complexes"
        },
        "Nombres relatifs": {
            "5e": "Introduction intuitive avec temp√©rature, altitude, calculs simples",
            "4e": "Op√©rations compl√®tes, r√®gles des signes, probl√®mes contextualis√©s",
            "3e": "Applications complexes, √©quations, in√©quations"
        },
        
        # Fran√ßais
        "R√©cits d'aventures": {
            "6e": "Lecture d'extraits d'aventures, compr√©hension du sch√©ma narratif, vocabulaire de l'action et du suspense"
        },
        "Grammaire - La phrase": {
            "6e": "Types et formes de phrases, ponctuation, reconnaissance sujet/verbe/compl√©ment"
        },
        "Le voyage et l'aventure : pourquoi aller vers l'inconnu ?": {
            "5e": "Analyse de textes narratifs, √©tude des motifs du d√©part, expression √©crite cr√©ative"
        },
        "Dire l'amour": {
            "4e": "Po√©sie lyrique, registres de langue, figures de style, expression des sentiments"
        },
        "Se raconter, se repr√©senter": {
            "3e": "Autobiographie, m√©moires, analyse de l'√©criture de soi, r√©flexion sur l'identit√©"
        },
        
        # Physique-Chimie
        "Mati√®re, mouvement, √©nergie, information": {
            "6e": "√âtats de la mati√®re, observations simples, classification des objets"
        },
        "Organisation et transformations de la mati√®re": {
            "5e": "M√©langes et corps purs, changements d'√©tat, transformations chimiques simples",
            "4e": "Atomes et mol√©cules, r√©actions chimiques, conservation de la masse",
            "3e": "Ions, pH, √©lectrolyse, synth√®se chimique"
        },
        "Mouvement et interactions": {
            "5e": "Description du mouvement, vitesse, interactions m√©caniques",
            "4e": "R√©f√©rentiel, relativit√© du mouvement, forces et effets",
            "3e": "Gravitation, poids et masse, interactions fondamentales"
        }
    }
    
    # Get specific guidance
    level_guide = niveau_guidance.get(niveau, "Adapter au niveau demand√©")
    chapter_guide = chapter_examples.get(chapitre, {}).get(niveau, "Respecter le programme officiel")
    
    # Build dynamic prompt context
    prompt_context = build_prompt_context(matiere, niveau, chapitre)
    
    # Math formatting rules for consistent LaTeX output
    MATH_FORMATTING_RULE = """
R√àGLE MATH√âMATIQUES OBLIGATOIRE - RESPECTER ABSOLUMENT:
- Toutes les fractions: \\frac{num√©rateur}{d√©nominateur} 
- Toutes les puissances: x^{exposant}
- Toutes les racines: \\sqrt{contenu}
- INTERDICTION ABSOLUE: "X de Y", "X par Y", "X/Y", HTML (<sup>, <sub>, <math>), s√©parateurs (-->, /)

EXEMPLES CORRECTS:
‚úÖ \\frac{7}{8} + \\frac{4}{5} = \\frac{35+32}{40} = \\frac{67}{40}
‚úÖ Calculer \\frac{15}{20} et simplifier
‚úÖ R√©soudre \\frac{2x}{5} = \\frac{3}{10}

EXEMPLES INTERDITS:
‚ùå 7 de 8, 7 par 8, 7/8
‚ùå 15 de 20, 2x par 5
‚ùå <sup>7</sup>/<sub>8</sub>

CRITIQUE: Utilise UNIQUEMENT la notation LaTeX \\frac{}{} pour TOUTES les fractions sans exception.
"""
    
    # Subject-specific instructions with dynamic prompt
    subject_instructions = {
        "Math√©matiques": f"""
{prompt_context['prompt_intro']}. 

Cr√©e {nb_exercices} exercices pour un √©l√®ve de {niveau} en {matiere}, en restant strictement sur le chapitre suivant: "{chapitre}". 
Chaque exercice doit avoir une difficult√© {difficulte}. Respecte parfaitement le programme scolaire fran√ßais pour ce niveau et cette comp√©tence.

{MATH_FORMATTING_RULE}

**Instructions cruciales** :
1. **DIVERSIT√â DES POINTS** : Utilise des lettres DIFF√âRENTES pour chaque exercice (D,E,F puis M,N,P puis X,Y,Z etc.) - JAMAIS tous A,B,C !
2. Utilise des **valeurs num√©riques diff√©rentes et vari√©es** pour chaque exercice (pas de r√©p√©tition des m√™mes donn√©es).
3. Le sch√©ma doit toujours √™tre plac√© dans `"donnees.schema"` et jamais dans `"enonce"`.
3. L‚Äô√©nonc√© doit contenir uniquement du texte lisible pour l‚Äô√©l√®ve et sa formulation doit √™tre clair comme il serait lu dans un manuel de math√©matique √† leur niveau.
4. Le sch√©ma doit suivre une structure claire (type, points, labels, segments, angles, etc.).
5. Les exercices ne doivent pas √™tre similaire dans la consigne varier comme dans un manuel d'exercice de math√©matique

**R√àGLE IMPORTANTE - DIVERSIT√â DES POINTS** :
Tu DOIS utiliser des lettres DIFF√âRENTES pour chaque exercice ! 
- Exercice 1 : points M, N, P ou D, E, F ou X, Y, Z
- Exercice 2 : autres lettres que l'exercice 1
- JAMAIS tous les exercices avec A, B, C !

**Format JSON attendu pour chaque exercice** :
{{
  "titre": "Titre concis",
  "enonce": "Dans le triangle DEF rectangle en E, DE = 5 cm et EF = 12 cm. Calculer la longueur DF.",
  "type": "geometry",
  "difficulte": "{difficulte}",
  "donnees": {{
    "schema": {{
      "type": "triangle_rectangle",
      "points": ["D", "E", "F"],
      "labels": {{"D": "(0,8)", "E": "(0,0)", "F": "(6,0)"}},
      "segments": [["D","E", {{"longueur": "5 cm"}}], ["E","F", {{"longueur": "12 cm"}}]],
      "angles": [["E", {{"angle_droit": true}}]]
    }}
  }},
  "solution": {{
    "etapes": ["Appliquer le th√©or√®me de Pythagore", "DF¬≤ = DE¬≤ + EF¬≤", "DF¬≤ = 5¬≤ + 12¬≤ = 25 + 144 = 169", "DF = ‚àö169 = 13 cm"],
    "resultat": "DF = 13 cm"
  }},
  "bareme": [
    {{"etape": "M√©thode", "points": 2.0}},
    {{"etape": "R√©sultat", "points": 2.0}}
  ]
}}

R√©ponds uniquement avec un tableau JSON contenant tous les exercices, sans texte ni explication suppl√©mentaire.
"""
,

        "Fran√ßais": f"""{prompt_context['prompt_intro']}.

G√©n√®re {nb_exercices} exercices pour un √©l√®ve de {niveau} en {matiere}, sur le chapitre suivant: "{chapitre}".
Chaque exercice doit avoir une difficult√© {difficulte}. Respecte parfaitement le programme scolaire fran√ßais pour ce niveau et cette comp√©tence.

R√àGLES FRAN√áAIS:
1. {level_guide}
2. Exercices vari√©s : analyse, grammaire, expression √©crite
3. Textes supports courts et adapt√©s au niveau {niveau}
4. Questions progressives et structur√©es
5. Respecter les attentes du programme pour "{chapitre}" """,

        "Physique-Chimie": f"""
{prompt_context['prompt_intro']}. 

Cr√©e {nb_exercices} exercices de Physique-Chimie pour un √©l√®ve de {niveau} sur le chapitre: "{chapitre}".
Chaque exercice doit avoir une difficult√© {difficulte}. Respecte parfaitement le programme scolaire fran√ßais.

R√àGLES PHYSIQUE-CHIMIE OBLIGATOIRES:
- Utilise des SITUATIONS CONCR√àTES et EXP√âRIMENTALES adapt√©es au niveau {niveau}
- Propose des CALCULS SIMPLES avec unit√©s (m, kg, s, J, V, A, etc.)
- Privil√©gie l'OBSERVATION et l'EXP√âRIMENTATION
- Utilise le VOCABULAIRE SCIENTIFIQUE appropri√© au niveau
- Les r√©ponses doivent √™tre en 2-3 √©tapes maximum
- Donne des valeurs num√©riques R√âALISTES et VARI√âES

EXEMPLES par chapitre:
- "Organisation et transformations de la mati√®re" : m√©langes, corps purs, r√©actions chimiques, atomes/mol√©cules
- "Mouvements et interactions" : vitesse, forces, frottements, gravit√© 
- "L'√©nergie et ses conversions" : √©nergie cin√©tique, potentielle, thermique, √©lectrique
- "Des signaux pour observer et communiquer" : lumi√®re, son, signaux √©lectriques

FORMAT JSON REQUIS:
{{
    "exercises": [
        {{
            "type": "experimental",
            "enonce": "√ânonc√© avec situation exp√©rimentale concr√®te",
            "icone": "atom",
            "solution": {{
                "etapes": ["√âtape 1: M√©thode/formule", "√âtape 2: Application num√©rique"],
                "resultat": "R√©sultat final avec unit√©"
            }},
            "difficulte": "{difficulte}",
            "bareme": [
                {{"etape": "M√©thode", "points": 1.5}},
                {{"etape": "Calcul", "points": 1.5}},
                {{"etape": "R√©sultat", "points": 1.0}}
            ]
        }}
    ]
}}
""",

        "SVT": f"""
{prompt_context['prompt_intro']}.

Cr√©e {nb_exercices} exercices de SVT pour un √©l√®ve de {niveau} sur le chapitre: "{chapitre}".
Chaque exercice doit avoir une difficult√© {difficulte}. Respecte parfaitement le programme scolaire fran√ßais.

R√àGLES SVT OBLIGATOIRES:
- Utilise des OBSERVATIONS et DONN√âES SCIENTIFIQUES r√©elles
- Privil√©gie l'ANALYSE et le RAISONNEMENT SCIENTIFIQUE
- Propose des SCH√âMAS BIOLOGIQUES simples quand pertinent 
- Utilise le VOCABULAIRE SCIENTIFIQUE adapt√© au niveau {niveau}
- D√©veloppe l'esprit critique et la d√©marche exp√©rimentale
- Les questions doivent favoriser la R√âFLEXION plus que le calcul

EXEMPLES par chapitre:
- "Le vivant et son √©volution" : classification, reproduction, g√©n√©tique, √©volution
- "Le corps humain et la sant√©" : nutrition, respiration, circulation, immunit√©
- "La plan√®te Terre, l'environnement" : g√©ologie, √©cosyst√®mes, climat, biodiversit√©

FORMAT JSON REQUIS:
{{
    "exercises": [
        {{
            "type": "analysis",
            "enonce": "√ânonc√© avec observation/document scientifique √† analyser",
            "icone": "leaf",
            "solution": {{
                "etapes": ["√âtape 1: Observation", "√âtape 2: Analyse", "√âtape 3: Conclusion"],
                "resultat": "Conclusion scientifique argument√©e"
            }},
            "difficulte": "{difficulte}",
            "bareme": [
                {{"etape": "Observation", "points": 1.0}},
                {{"etape": "Analyse", "points": 2.0}},
                {{"etape": "Conclusion", "points": 1.0}}
            ]
        }}
    ]
}}
""",

        "G√©ographie": f"""
{prompt_context['prompt_intro']}.

üó∫Ô∏è SP√âCIALISTE G√âOGRAPHIE - DIVERSIFICATION OBLIGATOIRE DES DOCUMENTS

Cr√©e {nb_exercices} exercices de G√©ographie pour un √©l√®ve de {niveau} sur le chapitre: "{chapitre}".
Chaque exercice doit avoir une difficult√© {difficulte}. Respecte parfaitement le programme scolaire fran√ßais.

‚ö†Ô∏è R√àGLE ABSOLUE - DIVERSIFICATION OBLIGATOIRE :
- CHAQUE EXERCICE DOIT UTILISER UN TYPE DE DOCUMENT DIFF√âRENT
- INTERDICTION FORMELLE d'utiliser le m√™me type 2 fois
- ANALYSER le contenu pour choisir le document le PLUS APPROPRI√â

TYPES DE DOCUMENTS DISPONIBLES (√Ä VARIER OBLIGATOIREMENT) :

1. "carte_france" ‚Üí Questions sur France, r√©gions, villes fran√ßaises
   Exemple : "Localise Paris, Lyon, Marseille sur une carte administrative"

2. "carte_europe" ‚Üí Questions sur pays europ√©ens, capitales, UE
   Exemple : "Identifie l'Allemagne, l'Italie et leurs capitales"

3. "carte_asie" ‚Üí Questions sur Asie, Chine, Japon, Inde
   Exemple : "Compare Tokyo et Beijing sur une carte d'Asie"

4. "carte_amerique_nord" ‚Üí Questions USA, Canada, Mexique
   Exemple : "Analyse l'urbanisation de la c√¥te est am√©ricaine"

5. "carte_afrique" ‚Üí Questions Afrique, Sahara, pays africains
   Exemple : "Localise le d√©sert du Sahara et le fleuve Nil"

6. "carte_monde" ‚Üí Questions globales, continents, oc√©ans
   Exemple : "Identifie les 5 oc√©ans sur un planisph√®re"

STRAT√âGIE DE DIVERSIFICATION FORC√âE :
- Exercice 1 : Choisir le type le PLUS PERTINENT selon le contenu
- Exercice 2 : Choisir un type DIFF√âRENT du pr√©c√©dent
- Exercice 3 : Encore DIFF√âRENT des 2 pr√©c√©dents
- Exercice 4 : DIFF√âRENT des 3 pr√©c√©dents

EXEMPLES CONCRETS DE DIVERSIFICATION :

Pour "{chapitre}" niveau {niveau} :

BATCH TYPE A - Chapitre sur la France :
- Ex1: carte_france + "Localise ta r√©gion sur la carte"
- Ex2: carte_europe + "Situe la France en Europe"  
- Ex3: carte_monde + "Place la France dans le monde"
- Ex4: carte_france + "Analyse les m√©tropoles fran√ßaises"

BATCH TYPE B - Chapitre sur l'urbanisation mondiale :
- Ex1: carte_monde + "Identifie les m√©galopoles mondiales"
- Ex2: carte_asie + "√âtudie l'urbanisation au Japon"
- Ex3: carte_amerique_nord + "Analyse les villes am√©ricaines"
- Ex4: carte_europe + "Compare Paris, Londres, Berlin"

FORMAT JSON OBLIGATOIRE AVEC DIVERSIFICATION :
{{
    "exercises": [
        {{
            "type": "cartographic",
            "enonce": "Exercice utilisant un premier type de document g√©ographique appropri√©",
            "icone": "map",
            "document_attendu": {{
                "type": "carte_france",
                "doit_afficher": ["√©l√©ments sp√©cifiques"],
                "langue": "fran√ßais",
                "description": "Description pr√©cise du document"
            }},
            "solution": {{
                "etapes": ["√âtape 1: Lecture", "√âtape 2: Analyse"],
                "resultat": "Conclusion g√©ographique"
            }},
            "difficulte": "{difficulte}"
        }},
        {{
            "type": "cartographic",
            "enonce": "Exercice utilisant un DEUXI√àME type DIFF√âRENT",
            "icone": "compass",
            "document_attendu": {{
                "type": "carte_europe",
                "doit_afficher": ["pays", "capitales"],
                "langue": "fran√ßais", 
                "description": "Carte europ√©enne avec focus sp√©cifique"
            }},
            "solution": {{
                "etapes": ["√âtape 1: Lecture", "√âtape 2: Analyse"],
                "resultat": "Conclusion g√©ographique"
            }},
            "difficulte": "{difficulte}"
        }},
        {{
            "type": "geographic",
            "enonce": "Exercice utilisant un TROISI√àME type DIFF√âRENT",
            "icone": "globe",
            "document_attendu": {{
                "type": "carte_monde",
                "doit_afficher": ["continents", "oc√©ans"],
                "langue": "fran√ßais",
                "description": "Planisph√®re mondial"
            }},
            "solution": {{
                "etapes": ["√âtape 1: Lecture", "√âtape 2: Analyse"],
                "resultat": "Conclusion g√©ographique"
            }},
            "difficulte": "{difficulte}"
        }},
        {{
            "type": "urban",
            "enonce": "Exercice utilisant un QUATRI√àME type DIFF√âRENT",
            "icone": "building-2", 
            "document_attendu": {{
                "type": "carte_asie",
                "doit_afficher": ["grandes villes", "densit√©"],
                "langue": "fran√ßais",
                "description": "Carte asiatique pour analyse urbaine"
            }},
            "solution": {{
                "etapes": ["√âtape 1: Lecture", "√âtape 2: Analyse"],
                "resultat": "Conclusion g√©ographique"
            }},
            "difficulte": "{difficulte}"
        }}
    ]
}}

CONTRAINTES ABSOLUES :
‚úÖ JAMAIS le m√™me "type" dans "document_attendu" entre exercices
‚úÖ Analyser le chapitre "{chapitre}" pour choisir les types pertinents
‚úÖ Varier : carte_france, carte_europe, carte_asie, carte_amerique_nord, carte_afrique, carte_monde
‚úÖ Cr√©er des √©nonc√©s coh√©rents avec le type de document choisi
‚úÖ {nb_exercices} exercices = {nb_exercices} types de documents DIFF√âRENTS garantis

R√âSULTAT ATTENDU CRITIQUE :
- PDF avec {nb_exercices} cartes visuellement DIFF√âRENTES
- Chaque exercice avec son document sp√©cifique et appropri√©
- Diversit√© g√©ographique maximale dans le m√™me batch
- Fin des r√©p√©titions de cartes identiques
"""
    }
    
    
    # Use the instruction (specialized or generic)
    # system_msg is already set above
    # GET THE SPECIALIZED INSTRUCTION FOR THE SUBJECT
    instruction = subject_instructions.get(matiere)
    
    if instruction:
        # Use specialized prompt
        logger.info(
            "üó∫Ô∏è Geography subject activated with advanced document integration",
            module_name="generation",
            func_name="geography_activation",
            features_enabled=["specialized_prompts", "document_search", "cartographic_exercises"],
            document_sources=["wikimedia_commons", "validated_cache", "fallback_system"],
            supported_document_types=["carte_france", "carte_monde", "carte_europe", "planisphere", "carte_thematique"]
        )
        system_msg = instruction
    else:
        # Fallback: Create a generic prompt for subjects without specialized prompts
        logger.warning(f"‚ö†Ô∏è No specialized prompt found for {matiere}, using generic prompt")
        instruction = f"""
{prompt_context['prompt_intro']}.

Cr√©e {nb_exercices} exercices de {matiere} pour un √©l√®ve de {niveau} sur le chapitre: "{chapitre}".
Chaque exercice doit avoir une difficult√© {difficulte}. Respecte parfaitement le programme scolaire fran√ßais.

R√àGLES G√âN√âRALES:
- Utilise un vocabulaire adapt√© au niveau {niveau}
- Propose des questions vari√©es et progressives
- Inclus des situations concr√®tes quand pertinent
- Structure tes r√©ponses en √©tapes claires
- Respecte les attentes p√©dagogiques fran√ßaises

FORMAT JSON REQUIS:
{{
    "exercises": [
        {{
            "type": "general",
            "enonce": "√ânonc√© de l'exercice adapt√© au niveau",
            "icone": "book-open",
            "solution": {{
                "etapes": ["√âtape 1: M√©thode", "√âtape 2: Application"],
                "resultat": "R√©ponse finale expliqu√©e"
            }},
            "difficulte": "{difficulte}",
            "bareme": [
                {{"etape": "M√©thode", "points": 2.0}},
                {{"etape": "Application", "points": 2.0}}
            ]
        }}
    ]
}}
"""
        system_msg = instruction
    
    # Create LLM chat instance with faster model
    chat = LlmChat(
        api_key=emergent_key,
        session_id=f"exercise_gen_{uuid.uuid4()}",
        system_message=f"""{system_msg}

JSON OBLIGATOIRE:
{{
  "exercises": [
    {{
      "type": "ouvert",
      "enonce": "√ânonc√© concis et clair",
      "difficulte": "{difficulte}",
      "solution": {{
        "etapes": ["√âtape 1", "√âtape 2"],
        "resultat": "R√©sultat final"
      }},
      "bareme": [
        {{"etape": "M√©thode", "points": 2.0}},
        {{"etape": "R√©sultat", "points": 2.0}}
      ]
    }}
  ]
}}"""
    ).with_model("openai", "gpt-4o")
    
    # Create concise prompt for faster generation
    examples = {
        # Math√©matiques
        "Volumes": "Calculer volume pav√© 4√ó3√ó2 cm",
        "Nombres relatifs": "Calculer -5 + 3 - (-2)",
        "Fractions": "Calculer 2/3 + 1/4",
        "G√©om√©trie - Figures planes": "Calculer p√©rim√®tre rectangle 5√ó3 cm",
        
        # Fran√ßais
        "R√©cits d'aventures": "Analyser un extrait de roman d'aventures",
        "Grammaire - La phrase": "Identifier sujet et verbe dans une phrase",
        "Conjugaison - Pr√©sent, pass√©, futur": "Conjuguer 'aller' au pr√©sent",
        "Le voyage et l'aventure : pourquoi aller vers l'inconnu ?": "Analyser les motivations d'un personnage",
        "Dire l'amour": "√âtudier une strophe de po√®me lyrique",
        "Se raconter, se repr√©senter": "Analyser un passage autobiographique",
        
        # Physique-Chimie
        "Organisation et transformations de la mati√®re": "Identifier une transformation chimique",
        "Constitution et transformations de la mati√®re": "Analyser la composition d'un m√©lange", 
        "Mouvements et interactions": "Calculer une vitesse moyenne",
        "Mouvement et interactions": "√âtudier les forces sur un objet",
        "L'√©nergie et ses conversions": "Convertir diff√©rentes formes d'√©nergie",
        "L'√©nergie : conversions et transferts": "Calculer l'√©nergie cin√©tique",
        "Des signaux pour observer et communiquer": "Analyser la propagation de la lumi√®re",
        "Ondes et signaux": "√âtudier les caract√©ristiques d'une onde",
        
        # SVT
        "La plan√®te Terre, l'environnement et l'action humaine": "Analyser l'impact humain sur un √©cosyst√®me",
        "Le vivant et son √©volution": "Classer des esp√®ces selon leurs caract√®res",
        "Le corps humain et la sant√©": "Expliquer le m√©canisme de la digestion",
        "La Terre, la vie et l'organisation du vivant": "Observer des cellules au microscope",
        "Les enjeux contemporains de la plan√®te": "√âtudier les changements climatiques",
        "Corps humain et sant√©": "Analyser le syst√®me immunitaire",
        
        # G√©ographie
        "D√©couvrir le(s) lieu(x) o√π j'habite": "Localiser sa commune sur une carte de France",
        "Se loger, travailler, se cultiver, avoir des loisirs": "Analyser l'organisation d'une ville fran√ßaise",
        "Satisfaire les besoins en √©nergie, en eau": "√âtudier la r√©partition des ressources en eau en France",
        "Se d√©placer - Moyens de transport": "Analyser les r√©seaux de transport fran√ßais",
        "Communiquer d'un bout √† l'autre du monde": "Localiser les grandes m√©tropoles mondiales",
        "Mieux habiter - La ville de demain": "Comparer l'urbanisation en France et dans le monde",
        "Mieux habiter - Les espaces ruraux": "Analyser les mutations des espaces ruraux fran√ßais",
        "L'urbanisation du monde": "Identifier les m√©galopoles sur un planisph√®re",
        "Les mobilit√©s humaines transnationales": "Analyser les flux migratoires sur une carte",
        "Des espaces transform√©s par la mondialisation": "√âtudier les √©changes commerciaux mondiaux"
    }
    
    example = examples.get(chapitre, f"Exercice {chapitre}")
    
    try:
        user_message = UserMessage(text=f"G√©n√®re {nb_exercices} exercices. Exemple: {example}")
        
        # FIRST PASS: Generate the exercise content
        logger.debug("Starting first AI pass - exercise content generation")
        log_ai_generation("first_pass_start", True)
        
        import asyncio
        response = await asyncio.wait_for(
            chat.send_message(user_message), 
            timeout=20.0  # 20 seconds max
        )
        
        logger.debug(f"First AI pass completed, response length: {len(response)} chars")
        
        # Parse the JSON response
        json_start = response.find('{')
        json_end = response.rfind('}') + 1
        if json_start == -1 or json_end == 0:
            raise ValueError("No JSON found in response")
            
        json_content = response[json_start:json_end]
        
        # JSON parsing with specific math symbol handling
        try:
            data = json.loads(json_content)
        except json.JSONDecodeError as e:
            logger.warning(f"JSON parsing error, attempting math symbol fix: {e}")
            
            # Fix common mathematical escape sequences that break JSON
            # These are often generated by AI when describing math formulas
            fixed_content = json_content
            fixed_content = fixed_content.replace('\\sqrt', 'sqrt')      # Remove backslash from sqrt
            fixed_content = fixed_content.replace('\\frac', 'frac')      # Remove backslash from frac
            fixed_content = fixed_content.replace('\\pi', 'œÄ')           # Replace \pi with œÄ
            fixed_content = fixed_content.replace('\\alpha', 'Œ±')        # Replace \alpha with Œ±
            fixed_content = fixed_content.replace('\\beta', 'Œ≤')         # Replace \beta with Œ≤
            fixed_content = fixed_content.replace('\\degree', '¬∞')       # Replace \degree with ¬∞
            
            # Fix other common escapes
            fixed_content = re.sub(r'\\([a-zA-Z])', r'\1', fixed_content)  # Remove backslashes before letters
            
            try:
                data = json.loads(fixed_content)
                logger.info("JSON fixed by removing math symbol escapes")
            except json.JSONDecodeError as e2:
                logger.error(f"JSON still invalid after math fixes: {e2}")
                logger.error(f"Full problematic JSON: {json_content}")
                
                # If still broken, use fallback
                logger.warning("Using fallback exercise generation due to persistent JSON errors")
                return await generate_fallback_exercises(matiere, niveau, chapitre, difficulte, nb_exercices)
        
        # Convert to Exercise objects with professional content processing
        exercises = []
        for i, ex_data in enumerate(data.get("exercises", [])):
            # Enrich with icon before processing - PASS MATIERE FOR NEW SUBJECTS
            ex_data = enrich_exercise_with_icon(ex_data, chapitre, matiere)
            
            # Get the raw enonce
            enonce = ex_data.get("enonce", "").strip()
            
            # SECOND PASS: Generate geometric schema if this is a geometry exercise
            if matiere.lower() == "math√©matiques":
                # Check if the exercise might need a geometric schema
                geometry_keywords = ["triangle", "cercle", "carr√©", "rectangle", "parall√©logramme", 
                                   "g√©om√©trie", "figure", "pythagore", "thal√®s", "trigonom√©trie", 
                                   "angle", "p√©rim√®tre", "aire", "longueur", "c√¥t√©", "hypot√©nuse"]
                
                if any(keyword in enonce.lower() for keyword in geometry_keywords):
                    logger.info(
                        "Geometry keywords detected, starting schema generation",
                        module_name="generation",
                        func_name="schema_detection",
                        enonce_preview=enonce[:100],
                        detected_keywords=[kw for kw in geometry_keywords if kw in enonce.lower()]
                    )
                    
                    # Generate schema with second AI call
                    log_ai_generation("second_pass_start", True)
                    schema_json_str = await generate_geometry_schema_with_ai(enonce)
                    
                    # Add schema to separate field (CLEAN DESIGN - no more JSON in text!)
                    if len(schema_json_str.strip()) > 10:  # More robust check for content
                        try:
                            # Validate the generated schema with STANDARDIZED format
                            schema_data = json.loads(schema_json_str)
                            schema_content = schema_data.get("schema")  # STANDARD KEY: "schema"
                            
                            if schema_content is not None and isinstance(schema_content, dict) and "type" in schema_content:
                                # Store schema in separate field - KEEP ENONCE PURE TEXT!
                                ex_data["geometric_schema"] = schema_content
                                ex_data["type"] = "geometry"
                                
                                log_schema_processing(
                                    schema_type=schema_content.get('type', 'unknown'),
                                    success=True,
                                    exercise_id=str(i+1)
                                )
                                logger.info(
                                    "Schema successfully stored in separate field",
                                    module_name="generation",
                                    func_name="schema_storage",
                                    schema_type=schema_content.get('type'),
                                    exercise_id=i+1
                                )
                            else:
                                logger.debug("No geometric schema needed for this exercise")
                                log_ai_generation("second_pass_skip", True)
                                
                        except json.JSONDecodeError as e:
                            logger.warning(f"‚ö†Ô∏è Invalid JSON schema generated: {e}, keeping text-only exercise")
            
            # CRITICAL FIX: Clean the enonce by removing any residual JSON schema blocks
            enonce_clean = re.sub(r'\{\s*"sch[√©e]ma".*?\}', "", enonce, flags=re.DOTALL)
            enonce_clean = re.sub(r'\{\s*"geometric_schema".*?\}', "", enonce_clean, flags=re.DOTALL)
            enonce_clean = enonce_clean.strip()
            
            # Remove any trailing newlines or multiple spaces caused by JSON removal
            enonce_clean = re.sub(r'\n\s*\n+', '\n\n', enonce_clean)  # Clean up multiple newlines
            enonce_clean = re.sub(r'\s+$', '', enonce_clean)  # Remove trailing whitespace
            
            if enonce_clean != enonce:
                logger.info(
                    "Cleaned JSON artifacts from enonce",
                    module_name="generation",
                    func_name="enonce_cleaning",
                    original_length=len(enonce),
                    cleaned_length=len(enonce_clean),
                    exercise_id=i+1
                )
            
            # THIRD PASS: Geographic document search for Geography exercises with DIVERSITY TRACKING
            if matiere.lower() == "g√©ographie" and "document_attendu" in ex_data:
                # Initialize document tracking if not exists
                if not hasattr(generate_exercises_with_ai, 'used_document_types'):
                    generate_exercises_with_ai.used_document_types = []
                
                logger.info(
                    "üó∫Ô∏è Geographic document search started",
                    module_name="generation",
                    func_name="document_search"
                )
                
                try:
                    # Passer l'√©nonc√© √† la recherche pour analyse intelligente
                    document_request = ex_data["document_attendu"].copy()
                    document_request["enonce"] = enonce_clean  # Ajouter l'√©nonc√© pour analyse
                    document_request["avoid_types"] = generate_exercises_with_ai.used_document_types.copy()  # Force diversification
                    
                    document_metadata = await search_educational_document(document_request)
                    if document_metadata:
                        # Add document to exercise data
                        ex_data["document"] = document_metadata
                        ex_data["type"] = "cartographic"  # Ensure type is set for Geography
                        
                        # Track the document type used to avoid repetition
                        doc_title = document_metadata.get("titre", "Unknown")
                        generate_exercises_with_ai.used_document_types.append(doc_title)
                        
                        logger.info(
                            "‚úÖ Educational document found and attached",
                            module_name="generation", 
                            func_name="document_attachment",
                            document_title=doc_title,
                            document_type=document_metadata.get("type", "Unknown"),
                            licence=document_metadata.get("licence", {}).get("type", "Unknown"),
                            exercise_id=i+1,
                            diversity_tracking=len(generate_exercises_with_ai.used_document_types),
                            content_based_selection=bool(document_request.get("enonce"))
                        )
                    else:
                        logger.warning(
                            "‚ö†Ô∏è No suitable geographic document found",
                            module_name="generation",
                            func_name="document_search_failure",
                            requested_type=ex_data["document_attendu"].get("type", "unknown")
                        )
                except Exception as e:
                    logger.error(
                        f"‚ùå Error during document search: {e}",
                        module_name="generation",
                        func_name="document_search_error",
                        exercise_id=i+1
                    )
            
            # Process the CLEANED enonce with centralized content processing
            processed_enonce = process_exercise_content(enonce_clean)
            
            # Process solution steps and result
            solution = ex_data.get("solution", {"etapes": ["√âtape 1", "√âtape 2"], "resultat": "R√©sultat"})
            
            # Process each solution step
            if "etapes" in solution and isinstance(solution["etapes"], list):
                solution["etapes"] = [
                    process_exercise_content(step) for step in solution["etapes"]
                ]
            
            # Process solution result
            if "resultat" in solution:
                solution["resultat"] = process_exercise_content(solution["resultat"])
            
            # CRITICAL FIX: Preserve geometric schema data and generate Base64 image
            schema_data = ex_data.get("geometric_schema", None)
            donnees_to_store = None
            schema_img_base64 = None
            
            if schema_data is not None:
                # Store schema in donnees for PDF processing
                donnees_to_store = {"schema": schema_data}
                logger.info(f"‚úÖ Geometric schema data preserved in donnees field: {schema_data.get('type', 'unknown')}")
                
                # CRITICAL: Generate Base64 image for frontend immediately
                schema_img_base64 = process_schema_to_base64(schema_data)
                if schema_img_base64:
                    # Check if Base64 already has data: prefix to avoid double prefix
                    if not schema_img_base64.startswith('data:'):
                        schema_img_base64 = f"data:image/png;base64,{schema_img_base64}"
                    logger.info(
                        "Schema Base64 generated during exercise creation",
                        module_name="generation",
                        func_name="create_exercise",
                        exercise_id=i+1,
                        schema_type=schema_data.get('type'),
                        base64_length=len(schema_img_base64)
                    )
            
            exercise = Exercise(
                type=ex_data.get("type", "ouvert"),
                enonce=processed_enonce,
                donnees=donnees_to_store,  # ‚úÖ PRESERVE SCHEMA DATA
                difficulte=ex_data.get("difficulte", difficulte),
                solution=solution,
                bareme=ex_data.get("bareme", [{"etape": "M√©thode", "points": 2.0}, {"etape": "R√©sultat", "points": 2.0}]),
                seed=hash(processed_enonce) % 1000000,
                # Add icon and exercise type information
                exercise_type=ex_data.get("type", "text"),
                icone=ex_data.get("icone", EXERCISE_ICON_MAPPING["default"]),
                # NEW: Clean geometric schema field (separate from text)
                geometric_schema=ex_data.get("geometric_schema", None),
                # CRITICAL: Base64 schema image for frontend
                schema_img=schema_img_base64,
                # NEW: Geographic document for Geography exercises
                document=ex_data.get("document", None)
            )
            exercises.append(exercise)
        
        if not exercises:
            raise ValueError("No exercises generated")
            
        logger.info(
            "Successfully completed AI exercise generation",
            module_name="generation",
            func_name="generate_exercises_with_ai",
            total_exercises=len(exercises),
            geometry_exercises=sum(1 for ex in exercises if hasattr(ex, 'exercise_type') and ex.exercise_type == 'geometry'),
            approach="two_pass"
        )
        
        # üó∫Ô∏è LOGS DE D√âBOGAGE DIVERSIT√â G√âOGRAPHIE (optimis√©)
        if matiere == "G√©ographie" and len(exercises) > 1:
            document_types_requested = []
            for exercise in exercises:
                if hasattr(exercise, 'document_attendu') and exercise.document_attendu:
                    if isinstance(exercise.document_attendu, dict):
                        doc_type = exercise.document_attendu.get('type', 'unknown')
                    else:
                        doc_type = str(exercise.document_attendu)
                    document_types_requested.append(doc_type)
            
            # V√©rifier la diversit√© rapidement
            unique_types = len(set(document_types_requested))
            total_types = len(document_types_requested)
            
            if unique_types < total_types:
                logger.warning(f"üéØ Geography diversity: {unique_types}/{total_types} types uniques")
            else:
                logger.info(f"‚úÖ Geography diversity: {unique_types}/{total_types} types diff√©rents")
        
        return exercises
        
    except asyncio.TimeoutError:
        logger.error("AI generation timeout - using fallback")
        return await generate_fallback_exercises(matiere, niveau, chapitre, difficulte, nb_exercices)
    except Exception as e:
        logger.error(f"Error generating exercises: {e}")
        return await generate_fallback_exercises(matiere, niveau, chapitre, difficulte, nb_exercices)

async def generate_fallback_exercises(matiere: str, niveau: str, chapitre: str, difficulte: str, nb_exercices: int) -> List[Exercise]:
    """Generate quick fallback exercises"""
    exercises = []
    
    # Quick templates based on chapter and subject
    templates = {
        # Math√©matiques
        "Nombres relatifs": [
            "Calculer : {a} + {b} - ({c})",
            "D√©terminer le signe de : {a} √ó {b}",
            "R√©soudre : x + {a} = {b}"
        ],
        "G√©om√©trie - Triangles et quadrilat√®res": [
            "Dans un triangle ABC, calculer l'aire sachant que AB = {a} cm, AC = {b} cm et l'angle A = 60¬∞.",
            "Un parall√©logramme ABCD a une base de {a} cm et une hauteur de {b} cm. Calculer son aire.",
            "Calculer le p√©rim√®tre d'un rectangle de longueur {a} cm et largeur {b} cm."
        ],
        "G√©om√©trie dans l'espace": [
            "Calculer le volume d'un cube d'ar√™te {a} cm.",
            "Un parall√©l√©pip√®de rectangle a pour dimensions {a} cm √ó {b} cm √ó {c} cm. Calculer son volume.",
            "Calculer l'aire totale d'un cube d'ar√™te {a} cm.",
            "Un cylindre a un rayon de {a} cm et une hauteur de {b} cm. Calculer son volume."
        ],
        "Volumes": [
            "Calculer le volume d'un pav√© de dimensions {a} cm √ó {b} cm √ó {c} cm",
            "Une bo√Æte cubique a une ar√™te de {a} cm. Quel est son volume ?",
            "Convertir {a} L en cm¬≥"
        ],
        "Th√©or√®me de Pythagore": [
            "Dans un triangle rectangle ABC rectangle en B, AB = {a} cm et BC = {b} cm. Calculer AC.",
            "Un triangle rectangle a des c√¥t√©s de {a} cm et {b} cm. Calculer l'hypot√©nuse.",
            "Utiliser le th√©or√®me de Pythagore pour calculer le c√¥t√© manquant : a = {a} cm, c = {b} cm."
        ],
        "Th√©or√®me de Thal√®s": [
            "Dans un triangle ABC, on trace une droite parall√®le √† BC. Si AB = {a} cm et la portion coup√©e = {b} cm, calculer les proportions.",
            "Deux droites parall√®les coupent deux s√©cantes. Si les segments sont {a} cm et {b} cm d'un c√¥t√©, et {c} cm de l'autre, calculer le quatri√®me segment.",
            "Utiliser le th√©or√®me de Thal√®s pour calculer une longueur manquante dans une configuration de triangles semblables."
        ],
        "Th√©or√®me de Thal√®s": [
            "Dans un triangle ABC, on trace une droite parall√®le √† BC. Si AB = {a} cm et la portion coup√©e = {b} cm, calculer les proportions.",
            "Deux droites parall√®les coupent deux s√©cantes. Si les segments sont {a} cm et {b} cm d'un c√¥t√©, et {c} cm de l'autre, calculer le quatri√®me segment.",
            "Utiliser le th√©or√®me de Thal√®s pour calculer une longueur manquante dans une configuration de triangles semblables."
        ],
        "Trigonom√©trie": [
            "Dans un triangle rectangle ABC rectangle en C, AB = {a} cm et AC = {b} cm. Calculer sin(A), cos(A) et tan(A).",
            "Un triangle rectangle a un angle de {a}¬∞ et une hypot√©nuse de {b} cm. Calculer les c√¥t√©s adjacents et oppos√©s.",
            "Utiliser les relations trigonom√©triques pour calculer la hauteur d'un b√¢timent sachant que l'angle d'√©l√©vation est {a}¬∞ √† {b} m de distance."
        ],
        "Fractions": [
            "Calculer : 1/{a} + 1/{b}",
            "Simplifier : {a}/{b}",
            "Comparer : 1/{a} et 1/{b}"
        ],
        
        # Fran√ßais
        "R√©cits d'aventures": [
            "Identifier les √©tapes du sch√©ma narratif dans un extrait",
            "Relever le vocabulaire de l'action dans le texte",
            "Expliquer les motivations du h√©ros"
        ],
        "Grammaire - La phrase": [
            "Identifier le sujet et le verbe dans la phrase",
            "Transformer la phrase en phrase interrogative",
            "Corriger les erreurs de ponctuation"
        ],
        "Conjugaison - Pr√©sent, pass√©, futur": [
            "Conjuguer le verbe au temps demand√©",
            "Identifier le temps des verbes soulign√©s",
            "Transformer la phrase au temps indiqu√©"
        ],
        
        # Physique-Chimie
        "Mati√®re, mouvement, √©nergie, information": [
            "Classer ces objets selon leur √©tat physique",
            "Identifier les propri√©t√©s de la mati√®re observ√©es",
            "D√©crire les changements observ√©s"
        ],
        "Organisation et transformations de la mati√®re": [
            "Identifier s'il s'agit d'un m√©lange ou d'un corps pur",
            "D√©crire la transformation observ√©e",
            "Expliquer le changement d'√©tat"
        ],
        "Mouvement et interactions": [
            "D√©crire le mouvement de l'objet",
            "Identifier les forces qui s'exercent",
            "Calculer la vitesse moyenne"
        ]
    }
    
    template_list = templates.get(chapitre, [f"Exercice sur {chapitre}"])
    
    for i in range(nb_exercices):
        # Use modulo to cycle through templates
        template = template_list[i % len(template_list)]
        
        # Simple random values
        import random
        a, b, c = random.randint(2, 9), random.randint(2, 9), random.randint(2, 9)
        
        enonce = template.format(a=a, b=b, c=c)
        
        # CRITICAL: Apply content processing to fallback exercises too
        processed_enonce = process_exercise_content(enonce)
        
        # Create fallback exercise data and enrich with icon
        fallback_data = {
            "enonce": processed_enonce,
            "type": "text",
            "icone": "book-open"
        }
        fallback_data = enrich_exercise_with_icon(fallback_data, chapitre, matiere)
        
        exercise = Exercise(
            type="ouvert",
            enonce=fallback_data["enonce"],
            donnees=None,
            difficulte=difficulte,
            solution={
                "etapes": [
                    process_exercise_content("Appliquer la m√©thode du cours"), 
                    process_exercise_content("Effectuer les calculs")
                ],
                "resultat": process_exercise_content("R√©sultat √† calculer")
            },
            bareme=[
                {"etape": "M√©thode", "points": 2.0},
                {"etape": "Calcul", "points": 2.0}
            ],
            seed=random.randint(1000, 9999),
            exercise_type=fallback_data.get("type", "text"),
            icone=fallback_data.get("icone", "book-open")
        )
        exercises.append(exercise)
    
    return exercises

def format_exercises_for_export(exercises: List[dict], options: AdvancedPDFOptions) -> str:
    """Format exercises with advanced options"""
    formatted_content = []
    
    for i, exercise in enumerate(exercises, 1):
        exercise_parts = []
        
        # Exercise number with custom formatting
        if options.show_exercise_numbers:
            if options.question_numbering == "roman":
                number = ["I", "II", "III", "IV", "V", "VI", "VII", "VIII", "IX", "X"][i-1] if i <= 10 else str(i)
            elif options.question_numbering == "letters":
                number = chr(64 + i) if i <= 26 else str(i)  # A, B, C...
            else:  # arabic or none
                number = str(i) if options.question_numbering == "arabic" else ""
            
            if number:
                exercise_parts.append(f"Exercice {number}")
        
        # Exercise content
        exercise_parts.append(exercise.get("enonce", ""))
        
        # Point values
        if options.show_point_values and exercise.get("bareme"):
            total_points = sum(item.get("points", 0) for item in exercise.get("bareme", []))
            if total_points > 0:
                exercise_parts.append(f"({total_points} points)")
        
        formatted_exercise = "\n".join(exercise_parts)
        
        # Exercise separator
        if options.exercise_separator == "line" and i < len(exercises):
            formatted_exercise += "\n" + "-" * 50 + "\n"
        elif options.exercise_separator == "space" and i < len(exercises):
            formatted_exercise += "\n\n"
        elif options.exercise_separator == "box":
            newline = '\n'
            lines = formatted_exercise.split(newline)
            box_width = len(lines[0]) + 4
            top_border = '‚îå' + '‚îÄ' * box_width + '‚îê'
            bottom_border = '‚îî' + '‚îÄ' * box_width + '‚îò'
            content_lines = newline.join([f'‚îÇ  {line}  ‚îÇ' for line in lines])
            formatted_exercise = f"{top_border}{newline}{content_lines}{newline}{bottom_border}"
        
        formatted_content.append(formatted_exercise)
    
    return "\n\n".join(formatted_content)

def format_solutions_for_export(exercises: List[dict], options: AdvancedPDFOptions) -> str:
    """Format solutions with advanced options"""
    formatted_content = []
    
    for i, exercise in enumerate(exercises, 1):
        solution_parts = []
        
        # Exercise number
        if options.show_exercise_numbers:
            if options.question_numbering == "roman":
                number = ["I", "II", "III", "IV", "V", "VI", "VII", "VIII", "IX", "X"][i-1] if i <= 10 else str(i)
            elif options.question_numbering == "letters":
                number = chr(64 + i) if i <= 26 else str(i)
            else:
                number = str(i) if options.question_numbering == "arabic" else ""
            
            if number:
                solution_parts.append(f"Solution {number}")
        
        # Solution content
        solution = exercise.get("solution", {})
        if solution.get("etapes"):
            solution_parts.extend(solution["etapes"])
        if solution.get("resultat"):
            solution_parts.append(f"R√©sultat: {solution['resultat']}")
        
        formatted_solution = "\n".join(solution_parts)
        formatted_content.append(formatted_solution)
    
    return "\n\n".join(formatted_content)

def get_template_colors_and_fonts(template_config: dict) -> dict:
    """Get template colors and fonts based on style"""
    style_name = template_config.get('template_style', 'minimaliste')
    template_style = TEMPLATE_STYLES.get(style_name, TEMPLATE_STYLES['minimaliste'])
    
    return {
        'template_colors': {
            'primary': template_style['primary_color'],
            'secondary': template_style['secondary_color'],
            'accent': template_style['accent_color']
        },
        'template_fonts': {
            'header': template_style['header_font'],
            'content': template_style['content_font']
        }
    }

async def generate_advanced_pdf(document: dict, content: str, export_type: str, template_config: dict, options: AdvancedPDFOptions) -> bytes:
    """Generate PDF with advanced layout options"""
    # Get layout settings
    page_format = PDF_LAYOUT_OPTIONS["page_formats"].get(options.page_format, PDF_LAYOUT_OPTIONS["page_formats"]["A4"])
    margins = options.custom_margins or PDF_LAYOUT_OPTIONS["margin_presets"].get(options.margin_preset, PDF_LAYOUT_OPTIONS["margin_presets"]["standard"])
    
    # Build CSS with advanced options
    advanced_css = f"""
        @page {{
            size: {page_format.get('width', '21cm')} {page_format.get('height', '29.7cm')};
            margin-top: {margins['top']};
            margin-bottom: {margins['bottom']};
            margin-left: {margins['left']};
            margin-right: {margins['right']};
        }}
        
        body {{
            font-size: {11 * options.font_scaling}pt;
            line-height: {1.4 * options.font_scaling};
        }}
        
        .header {{
            font-size: {18 * options.font_scaling}pt;
        }}
        
        .exercise-number {{
            font-weight: bold;
            color: #2c3e50;
            margin-top: 20px;
        }}
    """
    
    # Use Pro template if available
    if template_config:
        template_style = TEMPLATE_STYLES.get(template_config.get('template_style', 'minimaliste'), TEMPLATE_STYLES['minimaliste'])
        template_colors = get_template_colors_and_fonts(template_config)
        
        if export_type == "sujet":
            template_content = load_template("sujet_pro")
        else:
            template_content = load_template("corrige_pro")
        
        html_content = Template(template_content).render(
            document={
                **document,
                'exercices': content,
                'type_doc': export_type.title()
            },
            date_creation=datetime.now().strftime("%d/%m/%Y"),
            **template_config,
            **template_colors,
            advanced_css=advanced_css
        )
    else:
        # Fallback to standard template with advanced options
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                {advanced_css}
                /* Standard styling with advanced options */
                .content {{ white-space: pre-line; }}
                .document-info {{ font-size: {10 * options.font_scaling}pt; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>{export_type.title()}</h1>
                <h2>{document['matiere']} - {document['niveau']}</h2>
                <p>{document['chapitre']}</p>
                {f'<p>Difficult√©: {document["difficulte"]}</p>' if options.show_difficulty else ''}
                {f'<p>Cr√©√© le {datetime.now().strftime("%d/%m/%Y")}</p>' if options.show_creation_date else ''}
            </div>
            <div class="content">{content}</div>
        </body>
        </html>
        """
    
    # Generate PDF
    pdf_bytes = weasyprint.HTML(string=html_content).write_pdf()
    return pdf_bytes

# API Routes
@api_router.get("/")
async def root():
    return {"message": "API Le Ma√Ætre Mot V1 - G√©n√©rateur de documents p√©dagogiques"}

@api_router.get("/catalog")
async def get_catalog():
    """Get the complete curriculum catalog with feature flags"""
    logger.info("üó∫Ô∏è Catalog request - displaying all subjects with feature flags")
    
    # Get all subjects with their status and metadata
    all_subjects = get_all_subjects_with_status()
    
    catalog = []
    for matiere, subject_info in all_subjects.items():
        # Get curriculum data
        config = get_subject_by_name(matiere)
        if not config:
            continue
            
        levels = []
        # Only populate levels for active subjects
        if subject_info["status"] == "active" and config.get("data"):
            for niveau, themes in config["data"].items():
                # Flatten all chapters from all themes for the level
                all_chapters = []
                for theme, chapters in themes.items():
                    all_chapters.extend(chapters)
                    
                levels.append({
                    "name": niveau,
                    "chapters": all_chapters
                })
        
        catalog.append({
            "name": matiere,
            "status": subject_info["status"],
            "status_info": subject_info["status_info"],
            "expected": subject_info.get("expected", "TBD"),
            "description": subject_info.get("description", ""),
            "note": subject_info.get("note", ""),
            "features": subject_info.get("features", []),
            "chapter_count": subject_info["chapter_count"],
            "level_count": subject_info["level_count"],
            "levels": levels
        })
    
    # Get curriculum statistics
    stats = get_curriculum_stats()
    
    logger.info(
        f"üó∫Ô∏è Catalog served - {stats['total']['subjects']} subjects total, "
        f"{stats['active']['subject_count']} active, "
        f"{stats['total']['chapters']} chapters available"
    )
    
    return {
        "catalog": catalog,
        "stats": stats,
        "roadmap": {
            "active": stats["active"]["subject_count"],
            "coming_soon": stats["coming_soon"]["subject_count"], 
            "planned": stats["planned"]["subject_count"],
            "beta": stats["beta"]["subject_count"],
            "future": stats["future"]["subject_count"],
            "total_subjects": stats["total"]["subjects"],
            "total_chapters": stats["total"]["chapters"]
        }
    }

@api_router.get("/roadmap")
async def get_roadmap():
    """Get the public roadmap showing all subjects and their release timeline"""
    logger.info("üó∫Ô∏è Roadmap request - public transparency page")
    
    # Get subjects organized by status
    roadmap_data = {}
    for status in CURRICULUM_STATUS.keys():
        subjects_for_status = get_subjects_by_status(status)
        if subjects_for_status:
            roadmap_data[status] = {
                "status_info": CURRICULUM_STATUS[status],
                "subjects": []
            }
            
            for matiere, config in subjects_for_status.items():
                chapter_count = 0
                level_count = 0
                if config.get("data"):
                    level_count = len(config["data"])
                    for level_data in config["data"].values():
                        for chapters in level_data.values():
                            chapter_count += len(chapters)
                
                roadmap_data[status]["subjects"].append({
                    "name": matiere,
                    "description": config.get("description", ""),
                    "expected": config.get("expected", "TBD"),
                    "note": config.get("note", ""),
                    "features": config.get("features", []),
                    "chapter_count": chapter_count,
                    "level_count": level_count
                })
    
    # Get global statistics
    stats = get_curriculum_stats()
    
    return {
        "roadmap": roadmap_data,
        "stats": stats,
        "phases": {
            "phase_1": {
                "title": "üîÑ Octobre 2025 - Mati√®res Litt√©raires",
                "description": "Fran√ßais et EMC avec prompts IA sp√©cialis√©s", 
                "subjects": ["Fran√ßais", "EMC"],
                "status": "coming_soon"
            },
            "phase_2": {
                "title": "üìã Nov-D√©c 2025 - Sciences Humaines",
                "description": "Histoire, G√©ographie, SES avec supports documentaires",
                "subjects": ["Histoire", "G√©ographie", "SES", "Philosophie"],
                "status": "planned"
            },
            "phase_3": {
                "title": "üß™ Jan-Mars 2026 - Mati√®res Pratiques (Beta)",
                "description": "Tests utilisateurs avec retours enseignants",
                "subjects": ["EPS", "Enseignements artistiques", "Technologie"],
                "status": "beta"
            },
            "phase_4": {
                "title": "üîÆ 2026+ - Sp√©cialit√©s Avanc√©es",
                "description": "Mati√®res complexes n√©cessitant outils sp√©cialis√©s",
                "subjects": ["Sciences num√©riques", "Sp√©cialit√©s lyc√©e"],
                "status": "future"
            }
        }
    }

@api_router.get("/pricing")
async def get_pricing():
    """Get pricing packages"""
    return {"packages": PRICING_PACKAGES}

@api_router.get("/analytics/overview")
async def get_analytics_overview(request: Request):
    """Get basic analytics overview (Pro only)"""
    try:
        user_email = await require_pro_user(request)
        logger.info(f"Analytics overview requested by Pro user: {user_email}")
        
        # Get user's documents count
        user_documents = await db.documents.count_documents({"user_id": user_email})
        guest_documents = await db.documents.count_documents({"guest_id": {"$regex": f".*{user_email.split('@')[0]}.*"}})
        
        # Get user's exports count
        user_exports = await db.exports.count_documents({"user_email": user_email})
        
        # Get recent activity (last 30 days)
        thirty_days_ago = datetime.now(timezone.utc) - timedelta(days=30)
        recent_documents = await db.documents.count_documents({
            "$or": [{"user_id": user_email}, {"guest_id": {"$regex": f".*{user_email.split('@')[0]}.*"}}],
            "created_at": {"$gte": thirty_days_ago}
        })
        
        recent_exports = await db.exports.count_documents({
            "user_email": user_email,
            "created_at": {"$gte": thirty_days_ago}
        })
        
        # Get subject distribution
        subject_pipeline = [
            {"$match": {"$or": [{"user_id": user_email}, {"guest_id": {"$regex": f".*{user_email.split('@')[0]}.*"}}]}},
            {"$group": {"_id": "$matiere", "count": {"$sum": 1}}}
        ]
        subject_stats = await db.documents.aggregate(subject_pipeline).to_list(None)
        
        # Get template usage stats
        template_pipeline = [
            {"$match": {"user_email": user_email}},
            {"$group": {"_id": "$template_used", "count": {"$sum": 1}}}
        ]
        template_stats = await db.exports.aggregate(template_pipeline).to_list(None)
        
        return {
            "user_analytics": {
                "total_documents": user_documents + guest_documents,
                "total_exports": user_exports,
                "recent_activity": {
                    "documents_last_30_days": recent_documents,
                    "exports_last_30_days": recent_exports
                },
                "subject_distribution": [
                    {"subject": stat["_id"], "count": stat["count"]} 
                    for stat in subject_stats
                ],
                "template_usage": [
                    {"template": stat["_id"] or "standard", "count": stat["count"]} 
                    for stat in template_stats
                ],
                "subscription_info": {
                    "type": "Pro",
                    "analytics_enabled": True
                }
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching analytics overview: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la r√©cup√©ration des analytics")

@api_router.get("/analytics/usage")
async def get_usage_analytics(request: Request, days: int = 30):
    """Get detailed usage analytics over time (Pro only)"""
    try:
        user_email = await require_pro_user(request)
        logger.info(f"Usage analytics requested by Pro user: {user_email} for {days} days")
        
        # Calculate date range
        end_date = datetime.now(timezone.utc)
        start_date = end_date - timedelta(days=days)
        
        # Daily document generation
        daily_docs_pipeline = [
            {
                "$match": {
                    "$or": [{"user_id": user_email}, {"guest_id": {"$regex": f".*{user_email.split('@')[0]}.*"}}],
                    "created_at": {"$gte": start_date, "$lte": end_date}
                }
            },
            {
                "$group": {
                    "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                    "documents": {"$sum": 1}
                }
            },
            {"$sort": {"_id": 1}}
        ]
        daily_docs = await db.documents.aggregate(daily_docs_pipeline).to_list(None)
        
        # Daily exports
        daily_exports_pipeline = [
            {
                "$match": {
                    "user_email": user_email,
                    "created_at": {"$gte": start_date, "$lte": end_date}
                }
            },
            {
                "$group": {
                    "_id": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                    "exports": {"$sum": 1}
                }
            },
            {"$sort": {"_id": 1}}
        ]
        daily_exports = await db.exports.aggregate(daily_exports_pipeline).to_list(None)
        
        # Subject popularity over time
        subject_timeline_pipeline = [
            {
                "$match": {
                    "$or": [{"user_id": user_email}, {"guest_id": {"$regex": f".*{user_email.split('@')[0]}.*"}}],
                    "created_at": {"$gte": start_date, "$lte": end_date}
                }
            },
            {
                "$group": {
                    "_id": {
                        "date": {"$dateToString": {"format": "%Y-%m-%d", "date": "$created_at"}},
                        "subject": "$matiere"
                    },
                    "count": {"$sum": 1}
                }
            },
            {"$sort": {"_id.date": 1}}
        ]
        subject_timeline = await db.documents.aggregate(subject_timeline_pipeline).to_list(None)
        
        return {
            "usage_analytics": {
                "period": {
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                    "days": days
                },
                "daily_activity": {
                    "documents": [
                        {"date": doc["_id"], "count": doc["documents"]} 
                        for doc in daily_docs
                    ],
                    "exports": [
                        {"date": exp["_id"], "count": exp["exports"]} 
                        for exp in daily_exports
                    ]
                },
                "subject_timeline": [
                    {
                        "date": item["_id"]["date"], 
                        "subject": item["_id"]["subject"], 
                        "count": item["count"]
                    }
                    for item in subject_timeline
                ]
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching usage analytics: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la r√©cup√©ration des analytics d'usage")

@api_router.post("/generate")
async def generate_document(request: GenerateRequest):
    """Generate a document with exercises - CORRECTED feature flag validation"""
    try:
        logger = get_logger()
        logger.info(
            "üî• URGENT GENERATE REQUEST RECEIVED",
            module_name="generation",
            func_name="generate_document_corrected", 
            matiere=request.matiere,
            niveau=request.niveau,
            chapitre=request.chapitre,
            guest_id=request.guest_id
        )
        
        # CORRECTION 1: V√©rifier que la mati√®re existe dans le nouveau syst√®me
        if request.matiere not in CURRICULUM_DATA_COMPLETE:
            logger.error(f"‚ùå Unknown subject in CURRICULUM_DATA_COMPLETE: {request.matiere}")
            raise HTTPException(
                status_code=400,
                detail=f"Mati√®re '{request.matiere}' non reconnue dans le syst√®me"
            )
        
        # CORRECTION 2: V√©rifier le statut avec logs d√©taill√©s
        matiere_config = CURRICULUM_DATA_COMPLETE[request.matiere]
        matiere_status = matiere_config.get("status", "inactive")
        
        logger.info(
            f"üîç Feature flag check for {request.matiere}",
            status=matiere_status,
            expected=matiere_config.get("expected", "N/A"),
            has_data="data" in matiere_config
        )
        
        if matiere_status != "active":
            logger.warning(f"‚ö†Ô∏è Subject {request.matiere} is not active (status: {matiere_status})")
            
            log_feature_flag_access(request.matiere, matiere_status, "guest")
            
            raise HTTPException(
                status_code=423,  # Locked (not 400 Bad Request)
                detail={
                    "error": "subject_not_available", 
                    "message": f"La mati√®re {request.matiere} n'est pas encore disponible",
                    "status": matiere_status,
                    "expected": matiere_config.get("expected", "TBD"),
                    "available_subjects": list(get_active_subjects().keys())
                }
            )
        
        # Log active subject access
        log_feature_flag_access(request.matiere, "active", "guest")
        
        # CORRECTION 3: Utiliser les donn√©es du nouveau syst√®me directement
        subject_data = matiere_config.get("data", {})
        if not subject_data:
            logger.error(f"‚ùå No curriculum data for active subject: {request.matiere}")
            raise HTTPException(
                status_code=500,
                detail=f"Donn√©es de curriculum manquantes pour {request.matiere}"
            )
        
        # CORRECTION 4: Validation niveau avec le nouveau syst√®me
        available_levels = list(subject_data.keys())
        if request.niveau not in available_levels:
            logger.error(
                f"‚ùå Level not available: {request.niveau} for {request.matiere}",
                available_levels=available_levels
            )
            raise HTTPException(
                status_code=400,
                detail=f"Niveau '{request.niveau}' non disponible pour {request.matiere}. Disponibles: {', '.join(available_levels)}"
            )
        
        # CORRECTION 5: Validation chapitre avec le nouveau syst√®me 
        level_data = subject_data[request.niveau]
        all_chapters = []
        for theme, chapters in level_data.items():
            all_chapters.extend(chapters)
        
        if request.chapitre not in all_chapters:
            logger.error(
                f"‚ùå Chapter not available: {request.chapitre} for {request.matiere} {request.niveau}",
                available_chapters=all_chapters[:3]  # Show first 3 for logs
            )
            raise HTTPException(
                status_code=400, 
                detail=f"Chapitre '{request.chapitre}' non disponible pour {request.matiere} {request.niveau}"
            )
        
        logger.info(
            "‚úÖ All validations passed, starting exercise generation",
            module_name="generation",
            func_name="validation_success"
        )
        
        logger.info(f"üöÄ Document generation started - {request.matiere} {request.niveau} {request.chapitre} - {request.type_doc} - {request.difficulte} - {request.nb_exercices} exercises - guest_id: {request.guest_id}")
        
        exercises = await generate_exercises_with_ai(
            request.matiere,
            request.niveau,
            request.chapitre,
            request.type_doc,
            request.difficulte,
            request.nb_exercices
        )
        
        # Create document
        document = Document(
            guest_id=request.guest_id,
            matiere=request.matiere,
            niveau=request.niveau,
            chapitre=request.chapitre,
            type_doc=request.type_doc,
            difficulte=request.difficulte,
            nb_exercices=request.nb_exercices,
            exercises=exercises
        )
        
        # Save to database
        doc_dict = document.dict()
        # Convert datetime for MongoDB
        doc_dict['created_at'] = doc_dict['created_at'].isoformat()
        await db.documents.insert_one(doc_dict)
        
        # Return the document (already processed during generation)
        return {"document": document}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error generating document: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la g√©n√©ration du document")

@api_router.post("/auth/request-login")
async def request_login(request: LoginRequest):
    """Request a magic link for Pro user login"""
    try:
        # Check if user exists and is Pro
        is_pro, user = await check_user_pro_status(request.email)
        
        if not is_pro:
            # Don't reveal if user exists or not for security
            raise HTTPException(
                status_code=404, 
                detail="Utilisateur Pro non trouv√© ou abonnement expir√©"
            )
        
        # Generate magic link token (short-lived, 15 minutes)
        magic_token = str(uuid.uuid4()) + "-magic-" + str(int(datetime.now(timezone.utc).timestamp()))
        expires_at = datetime.now(timezone.utc) + timedelta(minutes=15)
        
        # Store magic token temporarily
        await db.magic_tokens.insert_one({
            "token": magic_token,
            "email": request.email,
            "expires_at": expires_at,
            "used": False,
            "created_at": datetime.now(timezone.utc)
        })
        
        # Send magic link email
        email_sent = await send_magic_link_email(request.email, magic_token)
        
        if not email_sent:
            raise HTTPException(
                status_code=500,
                detail="Erreur lors de l'envoi de l'email"
            )
        
        return {
            "message": "Lien de connexion envoy√© par email",
            "email": request.email
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in request login: {e}")
        raise HTTPException(
            status_code=500,
            detail="Erreur lors de la demande de connexion"
        )

@api_router.post("/auth/verify-login")
async def verify_login(request: VerifyLoginRequest):
    """Verify magic link token and create session"""
    try:
        logger.info(f"Attempting to verify login with token: {request.token[:20]}...")
        
        # Find magic token
        magic_token_doc = await db.magic_tokens.find_one({
            "token": request.token,
            "used": False
        })
        
        if not magic_token_doc:
            logger.warning(f"Magic token not found or already used: {request.token[:20]}...")
            
            # Check if token exists but is used
            used_token = await db.magic_tokens.find_one({"token": request.token})
            if used_token:
                logger.info("Token exists but is already used")
                raise HTTPException(
                    status_code=400,
                    detail="Token d√©j√† utilis√©"
                )
            else:
                logger.info("Token does not exist in database")
                raise HTTPException(
                    status_code=400,
                    detail="Token invalide"
                )
        
        logger.info(f"Magic token found for email: {magic_token_doc.get('email')}")
        
        # Check token expiration
        expires_at = magic_token_doc.get('expires_at')
        if isinstance(expires_at, str):
            expires_at = datetime.fromisoformat(expires_at).replace(tzinfo=timezone.utc)
        elif isinstance(expires_at, datetime) and expires_at.tzinfo is None:
            expires_at = expires_at.replace(tzinfo=timezone.utc)
            
        now = datetime.now(timezone.utc)
        
        if expires_at < now:
            logger.warning(f"Token expired: expires_at={expires_at}, now={now}")
            # Token expired
            await db.magic_tokens.delete_one({"token": request.token})
            raise HTTPException(
                status_code=400,
                detail="Token expir√©"
            )
        
        email = magic_token_doc.get('email')
        logger.info(f"Token is valid for email: {email}")
        
        # Verify user is still Pro
        is_pro, user = await check_user_pro_status(email)
        if not is_pro:
            logger.warning(f"User {email} is no longer Pro")
            raise HTTPException(
                status_code=403,
                detail="Abonnement Pro expir√©"
            )
        
        logger.info(f"User {email} confirmed as Pro")
        
        # Mark token as used
        await db.magic_tokens.update_one(
            {"token": request.token},
            {"$set": {"used": True, "used_at": datetime.now(timezone.utc)}}
        )
        logger.info(f"Magic token marked as used for {email}")
        
        # Create login session
        session_token = await create_login_session(email, request.device_id)
        
        if not session_token:
            logger.error("Failed to create login session")
            raise HTTPException(
                status_code=500,
                detail="Erreur lors de la cr√©ation de la session"
            )
        
        logger.info(f"Login session created successfully for {email}")
        
        return {
            "message": "Connexion r√©ussie",
            "email": email,
            "session_token": session_token,
            "expires_in": "24h"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in verify login: {e}")
        raise HTTPException(
            status_code=500,
            detail="Erreur lors de la v√©rification du token"
        )

@api_router.post("/auth/logout")
async def logout(request: Request):
    """Logout user by invalidating session"""
    try:
        # Get session token from header
        session_token = request.headers.get("X-Session-Token")
        
        if not session_token:
            raise HTTPException(
                status_code=400,
                detail="Token de session manquant"
            )
        
        # Remove session
        result = await db.login_sessions.delete_one({"session_token": session_token})
        
        if result.deleted_count == 0:
            raise HTTPException(
                status_code=404,
                detail="Session non trouv√©e"
            )
        
        return {"message": "D√©connexion r√©ussie"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error in logout: {e}")
        raise HTTPException(
            status_code=500,
            detail="Erreur lors de la d√©connexion"
        )

@api_router.get("/subscription/status/{email}")
async def get_subscription_status(email: str):
    """Get detailed subscription status for an email"""
    try:
        is_pro, user = await check_user_pro_status(email)
        
        if not is_pro or not user:
            return {
                "is_pro": False,
                "message": "Aucun abonnement actif trouv√© pour cette adresse email"
            }
        
        subscription_expires = user.get("subscription_expires")
        subscription_type = user.get("subscription_type", "inconnu")
        
        # Format dates
        if isinstance(subscription_expires, str):
            expires_date = datetime.fromisoformat(subscription_expires).replace(tzinfo=timezone.utc)
        elif isinstance(subscription_expires, datetime):
            expires_date = subscription_expires.replace(tzinfo=timezone.utc) if subscription_expires.tzinfo is None else subscription_expires
        else:
            expires_date = datetime.now(timezone.utc)
        
        now = datetime.now(timezone.utc)
        days_remaining = (expires_date - now).days
        
        return {
            "is_pro": True,
            "email": email,
            "subscription_type": subscription_type,
            "subscription_expires": expires_date.isoformat(),
            "expires_date_formatted": expires_date.strftime("%d/%m/%Y"),
            "days_remaining": max(0, days_remaining),
            "is_active": expires_date > now,
            "last_login": user.get("last_login"),
            "created_at": user.get("created_at")
        }
        
    except Exception as e:
        logger.error(f"Error getting subscription status for {email}: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la v√©rification du statut d'abonnement")

@api_router.get("/template/styles")
async def get_template_styles():
    """Get available template styles (public endpoint)"""
    return {
        "styles": {
            style_id: {
                "name": style["name"],
                "description": style["description"],
                "preview_colors": {
                    "primary": style["primary_color"],
                    "secondary": style["secondary_color"], 
                    "accent": style["accent_color"]
                }
            }
            for style_id, style in TEMPLATE_STYLES.items()
        }
    }

@api_router.get("/export/styles")
async def get_export_styles(request: Request):
    """Get available export template styles based on user status"""
    try:
        # Check if user is Pro
        session_token = request.headers.get("X-Session-Token")
        is_pro = False
        
        if session_token:
            email = await validate_session_token(session_token)
            if email:
                is_pro, _ = await check_user_pro_status(email)
        
        # Filter styles based on user status
        available_styles = {}
        for style_id, style in EXPORT_TEMPLATE_STYLES.items():
            if "free" in style["available_for"] or (is_pro and "pro" in style["available_for"]):
                available_styles[style_id] = {
                    "name": style["name"],
                    "description": style["description"],
                    "preview_image": style["preview_image"],
                    "pro_only": "free" not in style["available_for"]
                }
        
        return {
            "styles": available_styles,
            "user_is_pro": is_pro
        }
        
    except Exception as e:
        logger.error(f"Error getting export styles: {e}")
        # Return at least the free style on error
        return {
            "styles": {
                "classique": {
                    "name": "Classique",
                    "description": "Style traditionnel √©l√©gant",
                    "preview_image": "/api/template-previews/classique.png",
                    "pro_only": False
                }
            },
            "user_is_pro": False
        }

@api_router.get("/template/get")
async def get_user_template(request: Request):
    """Get user's template configuration (Pro only)"""
    try:
        user_email = await require_pro_user(request)
        
        # Find user template
        template_doc = await db.user_templates.find_one({"user_email": user_email})
        
        if not template_doc:
            # Return default template
            default_template = UserTemplate(
                user_email=user_email,
                template_style="minimaliste"
            )
            return default_template.dict()
        
        # Convert to UserTemplate object
        template = UserTemplate(**template_doc)
        template_dict = template.dict()
        
        # Migrate old logo URLs to new endpoint format
        if template_dict.get('logo_url') and template_dict['logo_url'].startswith('/uploads/logos/'):
            filename = template_dict['logo_url'].split('/')[-1]
            template_dict['logo_url'] = f"/api/logos/{filename}"
            logger.info(f"üîÑ Migrated logo URL for {user_email}: /uploads/logos/{filename} -> /api/logos/{filename}")
        
        return template_dict
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting user template: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors du chargement du template")

class TemplateSaveRequest(BaseModel):
    professor_name: Optional[str] = None
    school_name: Optional[str] = None
    school_year: Optional[str] = None
    footer_text: Optional[str] = None
    template_style: str = "minimaliste"

@api_router.post("/template/save")
async def save_user_template(
    request: Request,
    professor_name: Optional[str] = Form(None),
    school_name: Optional[str] = Form(None),
    school_year: Optional[str] = Form(None),
    footer_text: Optional[str] = Form(None),
    template_style: str = Form("minimaliste"),
    logo: Optional[UploadFile] = File(None)
):
    """Save user's template configuration (Pro only)"""
    try:
        user_email = await require_pro_user(request)
        
        # Debug logging
        logger.info(f"üîç Template save request for {user_email}: professor_name={professor_name}, school_name={school_name}, school_year={school_year}, footer_text={footer_text}, template_style={template_style}")
        
        # Handle logo upload
        logo_url = None
        logo_filename = None
        
        if logo and logo.filename:
            logger.info(f"üñºÔ∏è Logo upload detected: {logo.filename}, size: {logo.size}, content_type: {logo.content_type}")
            
            # Validate file type
            allowed_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp']
            if logo.content_type not in allowed_types:
                raise HTTPException(status_code=400, detail="Type de fichier non support√©. Utilisez JPG, PNG, GIF ou WebP.")
            
            # Validate file size (max 5MB)
            if logo.size and logo.size > 5 * 1024 * 1024:
                raise HTTPException(status_code=400, detail="Fichier trop volumineux. Taille maximum: 5MB.")
            
            # Create uploads directory if it doesn't exist
            uploads_dir = ROOT_DIR / "uploads" / "logos"
            uploads_dir.mkdir(parents=True, exist_ok=True)
            
            # Generate unique filename
            import uuid
            file_extension = logo.filename.split('.')[-1].lower()
            logo_filename = f"logo_{user_email.replace('@', '_').replace('.', '_')}_{uuid.uuid4().hex[:8]}.{file_extension}"
            logo_path = uploads_dir / logo_filename
            
            # Save file
            with open(logo_path, "wb") as buffer:
                content = await logo.read()
                buffer.write(content)
            
            # Create URL (relative path for serving)
            logo_url = f"/api/logos/{logo_filename}"
            logger.info(f"‚úÖ Logo saved: {logo_path} -> {logo_url}")
        
        # Validate template style
        if template_style not in TEMPLATE_STYLES:
            raise HTTPException(status_code=400, detail="Style de template invalide")
        
        # Get current template or create new one
        existing_template = await db.user_templates.find_one({"user_email": user_email})
        
        if existing_template:
            # Update existing
            update_data = {
                "professor_name": professor_name,
                "school_name": school_name,
                "school_year": school_year,
                "footer_text": footer_text,
                "template_style": template_style,
                "updated_at": datetime.now(timezone.utc)
            }
            
            # Add logo data if uploaded
            if logo_url:
                update_data["logo_url"] = logo_url
                update_data["logo_filename"] = logo_filename
            
            logger.info(f"üîç Updating existing template with data: {update_data}")
            
            await db.user_templates.update_one(
                {"user_email": user_email},
                {"$set": update_data}
            )
            
            # Get updated template
            updated_template = await db.user_templates.find_one({"user_email": user_email})
            template = UserTemplate(**updated_template)
        else:
            # Create new template
            template = UserTemplate(
                user_email=user_email,
                professor_name=professor_name,
                school_name=school_name,
                school_year=school_year,
                footer_text=footer_text,
                template_style=template_style,
                logo_url=logo_url,
                logo_filename=logo_filename
            )
            
            logger.info(f"üîç Creating new template: {template.dict()}")
            
            await db.user_templates.insert_one(template.dict())
        
        logger.info(f"Template saved for user: {user_email}")
        return {
            "message": "Template sauvegard√© avec succ√®s",
            "template": template.dict()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error saving user template: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la sauvegarde du template")

@api_router.get("/pdf/options")
async def get_pdf_options():
    """Get available PDF layout options (public endpoint)"""
    return {
        "layout_options": {
            "page_formats": [
                {"id": "A4", "name": "A4 Standard", "description": "Format A4 classique (21 √ó 29,7 cm)"},
                {"id": "A4_compact", "name": "A4 Compact", "description": "Format A4 avec marges r√©duites"},
                {"id": "US_Letter", "name": "US Letter", "description": "Format am√©ricain (8,5 √ó 11 pouces)"}
            ],
            "margin_presets": [
                {"id": "standard", "name": "Standard", "description": "Marges √©quilibr√©es (2,5cm haut/bas, 2cm gauche/droite)"},
                {"id": "compact", "name": "Compact", "description": "Marges r√©duites (1,5cm partout)"},
                {"id": "generous", "name": "G√©n√©reux", "description": "Marges importantes (3cm haut/bas, 2,5cm gauche/droite)"}
            ],
            "content_options": [
                {"id": "show_difficulty", "name": "Afficher la difficult√©", "default": True},
                {"id": "show_creation_date", "name": "Afficher la date de cr√©ation", "default": True},
                {"id": "show_exercise_numbers", "name": "Num√©roter les exercices", "default": True},
                {"id": "show_point_values", "name": "Afficher les bar√®mes", "default": True},
                {"id": "include_instructions", "name": "Inclure les consignes", "default": True}
            ],
            "visual_options": [
                {"id": "page_numbering", "name": "Num√©rotation des pages", "options": [
                    {"value": "bottom_center", "label": "Bas centr√©"},
                    {"value": "bottom_right", "label": "Bas droite"},
                    {"value": "top_right", "label": "Haut droite"},
                    {"value": "none", "label": "Aucune"}
                ]},
                {"id": "exercise_separator", "name": "S√©parateur d'exercices", "options": [
                    {"value": "line", "label": "Ligne"},
                    {"value": "space", "label": "Espace"},
                    {"value": "box", "label": "Encadr√©"},
                    {"value": "none", "label": "Aucun"}
                ]},
                {"id": "question_numbering", "name": "Num√©rotation des questions", "options": [
                    {"value": "arabic", "label": "1, 2, 3..."},
                    {"value": "roman", "label": "I, II, III..."},
                    {"value": "letters", "label": "a, b, c..."},
                    {"value": "none", "label": "Aucune"}
                ]}
            ]
        }
    }

@api_router.get("/quota/check")
@log_execution_time("check_quota_status")
async def check_quota_status(guest_id: str):
    """Check current quota status for guest user"""
    logger = get_logger()
    logger.info(
        "Checking quota status",
        module_name="quota",
        func_name="check_quota_status",
        user_type="guest",
        guest_id=guest_id[:8] + "..." if guest_id and len(guest_id) > 8 else guest_id
    )
    
    result = await check_guest_quota(guest_id)
    
    logger.info(
        "Quota check completed",
        module_name="quota",
        func_name="check_quota_status",
        user_type="guest",
        current_count=result.get("current_count", 0),
        limit=result.get("limit", 0),
        can_generate=result.get("can_generate", False)
    )
    
    return result
@api_router.get("/auth/session/validate")
async def validate_session(request: Request):
    """Validate current session and return user info"""
    try:
        session_token = request.headers.get("X-Session-Token")
        
        if not session_token:
            raise HTTPException(
                status_code=401,
                detail="Token de session manquant"
            )
        
        email = await validate_session_token(session_token)
        
        if not email:
            raise HTTPException(
                status_code=401,
                detail="Session invalide ou expir√©e"
            )
        
        # Check if user is still Pro
        is_pro, user = await check_user_pro_status(email)
        
        if not is_pro:
            # Clean up session if user is no longer Pro
            await db.login_sessions.delete_one({"session_token": session_token})
            raise HTTPException(
                status_code=403,
                detail="Abonnement Pro expir√©"
            )
        
        return {
            "email": email,
            "is_pro": True,
            "subscription_expires": user.get('subscription_expires'),
            "last_login": user.get('last_login')
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error validating session: {e}")
        raise HTTPException(
            status_code=500,
            detail="Erreur lors de la validation de session"
        )
async def check_quota_status(guest_id: str):
    """Check current quota status for guest user"""
    return await check_guest_quota(guest_id)

def get_template_colors_and_fonts(template_config):
    """Get CSS colors and fonts for WeasyPrint templates based on template configuration"""
    style_name = template_config.get('template_style', 'minimaliste')
    template_style = TEMPLATE_STYLES.get(style_name, TEMPLATE_STYLES['minimaliste'])
    
    return {
        'template_colors': {
            'primary': template_style['primary_color'],
            'secondary': template_style['secondary_color'],
            'accent': template_style['accent_color']
        },
        'template_fonts': {
            'header': template_style['header_font'].replace('-', ' '),
            'content': template_style['content_font'].replace('-', ' ')
        }
    }

@api_router.get("/logos/{filename}")
@api_router.head("/logos/{filename}")
async def serve_logo(filename: str):
    """Serve logo files for Pro users"""
    try:
        # Validate filename to prevent directory traversal
        if not filename or '..' in filename or '/' in filename:
            raise HTTPException(status_code=400, detail="Nom de fichier invalide")
        
        # Check if file exists
        logo_path = uploads_dir / "logos" / filename
        if not logo_path.exists():
            raise HTTPException(status_code=404, detail="Logo non trouv√©")
        
        # Determine content type based on file extension
        file_extension = filename.split('.')[-1].lower()
        content_type_map = {
            'png': 'image/png',
            'jpg': 'image/jpeg',
            'jpeg': 'image/jpeg',
            'gif': 'image/gif',
            'webp': 'image/webp'
        }
        
        content_type = content_type_map.get(file_extension, 'application/octet-stream')
        
        return FileResponse(
            path=str(logo_path),
            media_type=content_type,
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error serving logo {filename}: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors du chargement du logo")

@api_router.post("/export")
@log_execution_time("export_pdf")
async def export_pdf(request: ExportRequest, http_request: Request):
    """Export document as PDF using unified WeasyPrint approach"""
    logger = get_logger()
    
    logger.info(
        "Starting PDF export",
        module_name="export",
        func_name="export_pdf",
        doc_id=request.document_id,
        export_type=request.export_type,
        template_style=getattr(request, 'template_style', 'default')
    )
    
    try:
        # Check authentication - ONLY session token method (no legacy email fallback)
        session_token = http_request.headers.get("X-Session-Token")
        is_pro_user = False
        user_email = None
        template_config = {}
        
        # Authenticate using session token only
        if session_token:
            logger.info(f"Session token provided: {session_token[:20]}...")
            email = await validate_session_token(session_token)
            if email:
                logger.info(f"Session token validated for email: {email}")
                is_pro, user = await check_user_pro_status(email)
                is_pro_user = is_pro
                user_email = email
                logger.info(f"Pro status check result - email: {email}, is_pro: {is_pro}")
                
                # Load user template configuration if Pro
                if is_pro:
                    logger.info(f"Loading template config for Pro user: {email}")
                    try:
                        template_doc = await db.user_templates.find_one({"user_email": email})
                        logger.info(f"üîç Raw template doc from DB: {template_doc}")
                        if template_doc:
                            template_config = {
                                'template_style': template_doc.get('template_style', 'minimaliste'),
                                'professor_name': template_doc.get('professor_name'),
                                'school_name': template_doc.get('school_name'),
                                'school_year': template_doc.get('school_year'),
                                'footer_text': template_doc.get('footer_text'),
                                'logo_url': template_doc.get('logo_url'),
                                'logo_filename': template_doc.get('logo_filename')
                            }
                            logger.info(f"üîç Processed template config for {email}: {template_config}")
                            
                            # V√©rifier si on a des donn√©es r√©elles
                            has_real_data = any([
                                template_config.get('professor_name'),
                                template_config.get('school_name'),
                                template_config.get('school_year'),
                                template_config.get('footer_text')
                            ])
                            logger.info(f"üîç Template has real data: {has_real_data}")
                        else:
                            # Default template for Pro users
                            template_config = {'template_style': 'minimaliste'}
                            logger.info(f"Using default template for Pro user {email}")
                    except Exception as e:
                        logger.error(f"Error loading template config: {e}")
                        template_config = {'template_style': 'minimaliste'}
                else:
                    logger.info(f"User {email} is not Pro - using standard PDF generation")
            else:
                logger.info("Session token validation failed - treating as guest")
        else:
            logger.info("No session token provided - treating as guest user")
        
        # Pro users have unlimited exports
        if not is_pro_user:
            # Check guest quota
            if not request.guest_id:
                raise HTTPException(status_code=400, detail="Guest ID required for non-Pro users")
                
            quota_status = await check_guest_quota(request.guest_id)
            
            if quota_status["quota_exceeded"]:
                raise HTTPException(status_code=402, detail={
                    "error": "quota_exceeded", 
                    "message": "Limite de 3 exports gratuits atteinte. Passez √† l'abonnement Pro pour continuer.",
                    "action": "upgrade_required"
                })
        
        # Find the document
        doc = await db.documents.find_one({"id": request.document_id})
        if not doc:
            raise HTTPException(status_code=404, detail="Document non trouv√©")
        
        # CRITICAL: Process geometric schemas and LaTeX before PDF generation
        
        if 'exercises' in doc:
            for exercise in doc['exercises']:
                if 'enonce' in exercise and exercise['enonce']:
                    exercise['enonce'] = process_exercise_content(exercise['enonce'])
                    # Convert LaTeX math to MathML for PDF rendering
                    exercise['enonce'] = process_math_content_for_pdf(exercise['enonce'])
                
                # NEW: Generate SVG for schema if present in donnees
                if exercise.get('donnees') and isinstance(exercise['donnees'], dict):
                    schema_data = exercise['donnees'].get('schema')
                    if schema_data:
                        schema_type = schema_data.get('type', 'unknown')
                        logger.info(
                            "Generating SVG for PDF schema",
                            module_name="export",
                            func_name="generate_svg",
                            doc_id=request.document_id,
                            schema_type=schema_type
                        )
                        
                        svg_content = schema_renderer.render_to_svg(schema_data)
                        if svg_content:
                            exercise['schema_svg'] = svg_content
                            logger.info(
                                "SVG generated successfully for PDF",
                                module_name="export",
                                func_name="generate_svg",
                                doc_id=request.document_id,
                                schema_type=schema_type,
                                svg_length=len(svg_content),
                                status="success"
                            )
                            log_schema_processing(schema_type, True, doc_id=request.document_id)
                        else:
                            logger.warning(
                                "Failed to generate SVG for PDF schema",
                                module_name="export",
                                func_name="generate_svg",
                                doc_id=request.document_id,
                                schema_type=schema_type,
                                status="failed"
                            )
                            log_schema_processing(schema_type, False, doc_id=request.document_id)
                            exercise['schema_svg'] = ""
                    else:
                        exercise['schema_svg'] = ""
                else:
                    exercise['schema_svg'] = ""
                
                # NOUVEAU: Process geographic document if present
                if exercise.get('document'):
                    doc_data = exercise['document']
                    logger.info(
                        "üó∫Ô∏è Processing geographic document for PDF export",
                        module_name="export",
                        func_name="process_geographic_document",
                        doc_id=request.document_id,
                        exercise_id=exercise.get('id', 'unknown'),
                        document_title=doc_data.get('titre', 'Unknown'),
                        document_type=doc_data.get('type', 'Unknown'),
                        has_image=bool(doc_data.get('url_fichier_direct')),
                        image_url=doc_data.get('url_fichier_direct', 'No URL')[:100] if doc_data.get('url_fichier_direct') else None,
                        licence_type=doc_data.get('licence', {}).get('type', 'Unknown'),
                        licence_attribution=doc_data.get('licence', {}).get('notice_attribution', 'No attribution')[:50] if doc_data.get('licence', {}).get('notice_attribution') else None
                    )
                    
                    # Validate document data for PDF rendering
                    if not doc_data.get('url_fichier_direct'):
                        logger.warning(
                            "‚ö†Ô∏è Geographic document missing image URL",
                            module_name="export",
                            func_name="document_validation",
                            doc_id=request.document_id,
                            document_title=doc_data.get('titre', 'Unknown')
                        )
                    
                    if not doc_data.get('licence', {}).get('notice_attribution'):
                        logger.warning(
                            "‚ö†Ô∏è Geographic document missing attribution",
                            module_name="export",
                            func_name="document_validation",
                            doc_id=request.document_id,
                            document_title=doc_data.get('titre', 'Unknown')
                        )
                else:
                    logger.debug(
                        "No geographic document for exercise",
                        module_name="export",
                        func_name="process_geographic_document",
                        exercise_id=exercise.get('id', 'unknown')
                    )
                
                # Process solution if it exists
                if exercise.get('solution'):
                    if exercise['solution'].get('resultat'):
                        exercise['solution']['resultat'] = process_exercise_content(exercise['solution']['resultat'])
                        
                    if exercise['solution'].get('etapes') and isinstance(exercise['solution']['etapes'], list):
                        exercise['solution']['etapes'] = [
                            process_exercise_content(step) for step in exercise['solution']['etapes']
                        ]
            

        # Convert to Document object
        if isinstance(doc.get('created_at'), str):
            doc['created_at'] = datetime.fromisoformat(doc['created_at'])
        document = Document(**doc)
        
        # NEW TEMPLATE STYLE SYSTEM - Choose template based on requested style
        requested_style = request.template_style or "classique"
        logger.info(f"üé® TEMPLATE STYLE EXPORT - Requested style: {requested_style}, Pro user: {is_pro_user}")
        
        # Validate style permission
        if requested_style not in EXPORT_TEMPLATE_STYLES:
            logger.warning(f"Invalid template style: {requested_style}, falling back to classique")
            requested_style = "classique"
        
        style_config = EXPORT_TEMPLATE_STYLES[requested_style]
        
        # Check if user has permission for this style
        if "free" not in style_config["available_for"] and not is_pro_user:
            logger.info(f"Style {requested_style} is Pro-only, user is not Pro. Using classique instead.")
            requested_style = "classique"
            style_config = EXPORT_TEMPLATE_STYLES["classique"]
        
        # Choose the correct template file
        if request.export_type == "sujet":
            template_name = style_config["sujet_template"]
        else:
            template_name = style_config["corrige_template"]
        
        logger.info(f"üìÑ Using template: {template_name} for style: {requested_style}")
        template_content = load_template(template_name)
        
        # Prepare render context
        render_context = {
            'document': document,
            'date_creation': datetime.now(timezone.utc).strftime("%d/%m/%Y"),
        }
        
        # Add Pro personalization if available
        if is_pro_user and template_config:
            render_context['template_config'] = template_config
            render_context['school_name'] = template_config.get('school_name')
            render_context['professor_name'] = template_config.get('professor_name')
            render_context['school_year'] = template_config.get('school_year')
            render_context['footer_text'] = template_config.get('footer_text')
            render_context['logo_filename'] = template_config.get('logo_filename')
            
            # Convert logo URL to absolute file path for WeasyPrint
            logo_url = template_config.get('logo_url')
            if logo_url and logo_url.startswith('/uploads/'):
                logo_file_path = ROOT_DIR / logo_url[1:]  # Remove leading slash
                if logo_file_path.exists():
                    absolute_logo_url = f"file://{logo_file_path}"
                    render_context['logo_url'] = absolute_logo_url
                    template_config['logo_url'] = absolute_logo_url
                    logger.info(f"‚úÖ Logo converted for WeasyPrint: {logo_file_path}")
                else:
                    logger.warning(f"‚ö†Ô∏è Logo file not found: {logo_file_path}")
                    render_context['logo_url'] = None
                    template_config['logo_url'] = None
            else:
                render_context['logo_url'] = logo_url
            
            logger.info(f"üîç FINAL RENDER CONTEXT FOR PRO USER:")
            logger.info(f"   school_name: {render_context.get('school_name')}")
            logger.info(f"   professor_name: {render_context.get('professor_name')}")
            logger.info(f"   logo_url: {render_context.get('logo_url')}")
       
        # Generate filename with style suffix
        filename = f"LeMaitremot_{document.type_doc}_{document.matiere}_{document.niveau}_{request.export_type}_{requested_style}.pdf"
        
        # Process LaTeX expressions in document before rendering
        logger.info("üî¨ Converting LaTeX expressions to SVG...")
        
        # Convert document to dict for processing (to avoid Pydantic read-only issues)
        document_dict = document.dict()
        
        # Process each exercise and convert LaTeX to SVG
        try:
            for exercise in document_dict.get('exercises', []):
                # Process exercise statement
                if 'enonce' in exercise and exercise['enonce']:
                    # First process geometric schemas, then LaTeX
                    exercise['enonce'] = geometry_renderer.process_geometric_schemas(exercise['enonce'])
                    exercise['enonce'] = latex_renderer.convert_latex_to_svg(exercise['enonce'])
                
                # Process QCM options if they exist
                if (exercise.get('type') == 'qcm' and 
                    exercise.get('donnees') and 
                    exercise['donnees'].get('options')):
                    exercise['donnees']['options'] = [
                        latex_renderer.convert_latex_to_svg(
                            geometry_renderer.process_geometric_schemas(option)
                        )
                        for option in exercise['donnees']['options']
                    ]
                
                # Process solution if it exists
                if exercise.get('solution'):
                    # Process result
                    if exercise['solution'].get('resultat'):
                        processed_result = geometry_renderer.process_geometric_schemas(
                            exercise['solution']['resultat']
                        )
                        exercise['solution']['resultat'] = latex_renderer.convert_latex_to_svg(
                            processed_result
                        )
                    # Process steps
                    if exercise['solution'].get('etapes') and isinstance(exercise['solution']['etapes'], list):
                        exercise['solution']['etapes'] = [
                            latex_renderer.convert_latex_to_svg(
                                geometry_renderer.process_geometric_schemas(step)
                            )
                            for step in exercise['solution']['etapes']
                        ]
        
        except Exception as e:
            logger.error(f"Error during LaTeX to SVG conversion: {e}")
            # Continue with original document if conversion fails
            document_dict = document.dict()
        
        # Update render context with processed document
        render_context['document'] = document_dict
        
        # Generate SVG schemas for each exercise (before template render)
        exercises = document_dict.get('exercises', [])
        for i, exercise in enumerate(exercises, start=1):
            schema_data = None
            
            # Check for schema in donnees
            if exercise.get('donnees') and isinstance(exercise.get('donnees'), dict):
                schema_data = exercise.get('donnees').get('schema')
            
            if schema_data:
                try:
                    svg_content = schema_renderer.render_to_svg(schema_data)
                    if svg_content:
                        exercise['schema_svg'] = svg_content
                        logger.info(f"[EXPORT][PDF] Generated SVG for Exercice {i} - schema_svg length = {len(svg_content)}")
                    else:
                        logger.warning(f"[EXPORT][PDF] Failed to render schema for Exercice {i}")
                except Exception as e:
                    logger.error(f"[EXPORT][PDF] Error rendering schema for Exercice {i}: {e}")
        
        # Log schema_svg presence for debugging
        for i, ex in enumerate(exercises, start=1):
            schema_svg_length = len(ex.get('schema_svg', ''))
            logger.info(f"[EXPORT][PDF] Exercice {i} - schema_svg length = {schema_svg_length}")
        
        # Render HTML using Jinja2
        logger.info("üîß Generating PDF with WeasyPrint...")
        template = Template(template_content)
        html_content = template.render(**render_context)
        
        logger.info("‚úÖ Mathematical expressions converted to SVG")
        
        # Generate PDF with WeasyPrint
        pdf_bytes = weasyprint.HTML(string=html_content).write_pdf()
        
        # Create temporary file
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
        temp_file.write(pdf_bytes)
        temp_file.close()
        
        # Track export for guest quota (only for non-Pro users)
        if not is_pro_user and request.guest_id:
            export_record = {
                "id": str(uuid.uuid4()),
                "document_id": request.document_id,
                "export_type": request.export_type,
                "guest_id": request.guest_id,
                "user_email": user_email,
                "is_pro": is_pro_user,
                "template_used": template_config.get('template_style') if template_config else 'standard',
                "created_at": datetime.now(timezone.utc)
            }
            await db.exports.insert_one(export_record)
        
        logger.info(f"‚úÖ PDF generated successfully: {filename}")
        
        return FileResponse(
            temp_file.name,
            media_type='application/pdf',
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error exporting PDF: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de l'export PDF")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error exporting PDF: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de l'export PDF")

@api_router.post("/export/advanced")
async def export_pdf_advanced(request: EnhancedExportRequest, http_request: Request):
    """Export document as PDF with advanced layout options (Pro only)"""
    try:
        # Check authentication - Pro only feature
        session_token = http_request.headers.get("X-Session-Token")
        if not session_token:
            raise HTTPException(status_code=401, detail="Session token requis pour les options avanc√©es")
        
        email = await validate_session_token(session_token)
        if not email:
            raise HTTPException(status_code=401, detail="Session token invalide")
        
        is_pro, user = await check_user_pro_status(email)
        if not is_pro:
            raise HTTPException(status_code=403, detail="Fonctionnalit√© Pro uniquement")
        
        logger.info(f"Advanced PDF export requested by Pro user: {email}")
        
        # Get document
        document = await db.documents.find_one({"id": request.document_id})
        if not document:
            raise HTTPException(status_code=404, detail="Document non trouv√©")
        
        # CRITICAL: Process geometric schemas and LaTeX before PDF generation
        if 'exercises' in document:
            for exercise in document['exercises']:
                if 'enonce' in exercise and exercise['enonce']:
                    exercise['enonce'] = process_exercise_content(exercise['enonce'])
                
                # Process solution if it exists
                if exercise.get('solution'):
                    if exercise['solution'].get('resultat'):
                        exercise['solution']['resultat'] = process_exercise_content(exercise['solution']['resultat'])
                        # Convert LaTeX math to MathML for PDF rendering
                        exercise['solution']['resultat'] = process_math_content_for_pdf(exercise['solution']['resultat'])
                        
                    if exercise['solution'].get('etapes') and isinstance(exercise['solution']['etapes'], list):
                        processed_steps = []
                        for step in exercise['solution']['etapes']:
                            processed_step = process_exercise_content(step)
                            # Convert LaTeX math to MathML for PDF rendering
                            processed_step = process_math_content_for_pdf(processed_step)
                            processed_steps.append(processed_step)
                        exercise['solution']['etapes'] = processed_steps
        
        # Load user template configuration
        template_config = {}
        template_doc = await db.user_templates.find_one({"user_email": email})
        if template_doc:
            template_config = {
                'template_style': template_doc.get('template_style', 'minimaliste'),
                'professor_name': template_doc.get('professor_name'),
                'school_name': template_doc.get('school_name'),
                'school_year': template_doc.get('school_year'),
                'footer_text': template_doc.get('footer_text'),
                'logo_url': template_doc.get('logo_url'),
                'logo_filename': template_doc.get('logo_filename')
            }
        else:
            template_config = {'template_style': 'minimaliste'}
        
        # Apply advanced options
        advanced_opts = request.advanced_options or AdvancedPDFOptions()
        
        # Generate content with advanced formatting
        if request.export_type == "sujet":
            content = format_exercises_for_export(document["exercises"], advanced_opts)
        else:  # corrige
            content = format_solutions_for_export(document["exercises"], advanced_opts)
        
        # Generate PDF with advanced layout
        pdf_content = await generate_advanced_pdf(
            document, content, request.export_type, template_config, advanced_opts
        )
        
        # Create temporary file
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
        temp_file.write(pdf_content)
        temp_file.close()
        
        # Generate filename
        filename = f"LeMaitremot_{request.export_type}_{document['matiere']}_{document['niveau']}_advanced.pdf"
        
        # Record export
        export_record = {
            "id": str(uuid.uuid4()),
            "document_id": request.document_id,
            "export_type": request.export_type,
            "user_email": email,
            "is_pro": True,
            "template_used": template_config.get('template_style', 'minimaliste'),
            "advanced_options": advanced_opts.dict(),
            "created_at": datetime.now(timezone.utc)
        }
        await db.exports.insert_one(export_record)
        
        logger.info(f"‚úÖ Advanced PDF generated successfully: {filename}")
        
        return FileResponse(
            temp_file.name,
            media_type='application/pdf',
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error exporting advanced PDF: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de l'export PDF avanc√©")

@api_router.post("/checkout/session")
async def create_checkout_session(request: CheckoutRequest, http_request: Request):
    """Create Stripe checkout session"""
    try:
        # Validate package
        if request.package_id not in PRICING_PACKAGES:
            raise HTTPException(status_code=400, detail="Package invalide")
        
        # Check if email is already subscribed (anti-duplicate protection)
        if request.email:
            is_pro, existing_user = await check_user_pro_status(request.email)
            if is_pro and existing_user:
                subscription_expires = existing_user.get("subscription_expires")
                subscription_type = existing_user.get("subscription_type", "inconnu")
                
                # Format expiration date for display
                if isinstance(subscription_expires, str):
                    expires_date = datetime.fromisoformat(subscription_expires).replace(tzinfo=timezone.utc)
                elif isinstance(subscription_expires, datetime):
                    expires_date = subscription_expires.replace(tzinfo=timezone.utc) if subscription_expires.tzinfo is None else subscription_expires
                else:
                    expires_date = datetime.now(timezone.utc) + timedelta(days=30)  # fallback
                
                formatted_date = expires_date.strftime("%d/%m/%Y")
                
                logger.info(f"Duplicate subscription attempt for {request.email} - already Pro until {formatted_date}")
                
                raise HTTPException(
                    status_code=409,  # Conflict
                    detail={
                        "error": "already_subscribed",
                        "message": f"Cette adresse email dispose d√©j√† d'un abonnement {subscription_type} actif jusqu'au {formatted_date}. Pour modifier votre abonnement, veuillez nous contacter.",
                        "subscription_type": subscription_type,
                        "expires_date": formatted_date,
                        "action": "contact_support"
                    }
                )
        
        package = PRICING_PACKAGES[request.package_id]
        logger.info(f"Creating checkout session for package: {package}")
        
        # Initialize Stripe
        host_url = str(http_request.base_url).rstrip('/')
        webhook_url = f"{host_url}/api/webhook/stripe"
        stripe_checkout = StripeCheckout(api_key=stripe_secret_key, webhook_url=webhook_url)
        
        # Build URLs from frontend origin
        success_url = f"{request.origin_url}/success?session_id={{CHECKOUT_SESSION_ID}}"
        cancel_url = f"{request.origin_url}/cancel"
        
        # Prepare metadata
        metadata = {
            "package_id": request.package_id,
            "email": request.email or "",
            "nom": request.nom or "",
            "etablissement": request.etablissement or "",
            "source": "lemaitremot_web"
        }
        
        # Create checkout session request
        checkout_request = CheckoutSessionRequest(
            amount=package["amount"],
            currency=package["currency"],
            success_url=success_url,
            cancel_url=cancel_url,
            metadata=metadata
        )
        
        # Create session
        session = await stripe_checkout.create_checkout_session(checkout_request)
        
        # Store transaction
        transaction = PaymentTransaction(
            session_id=session.session_id,
            amount=package["amount"],
            currency=package["currency"],
            package_id=request.package_id,
            email=request.email,
            metadata=metadata,
            payment_status="pending",
            session_status="initiated"
        )
        
        # Save to database
        await db.payment_transactions.insert_one(transaction.dict())
        
        logger.info(f"Checkout session created: {session.session_id}")
        
        return {
            "url": session.url,
            "session_id": session.session_id
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating checkout session: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la cr√©ation de la session")

@api_router.get("/checkout/status/{session_id}")
async def get_checkout_status(session_id: str):
    """Get checkout session status"""
    try:
        # Initialize Stripe
        stripe_checkout = StripeCheckout(api_key=stripe_secret_key, webhook_url="")
        
        # Get status from Stripe
        status = await stripe_checkout.get_checkout_status(session_id)
        
        # Find transaction in database
        transaction = await db.payment_transactions.find_one({"session_id": session_id})
        
        if not transaction:
            raise HTTPException(status_code=404, detail="Transaction non trouv√©e")
        
        # Update transaction status if payment completed
        if status.payment_status == "paid" and transaction.get("payment_status") != "paid":
            # Update transaction
            await db.payment_transactions.update_one(
                {"session_id": session_id},
                {
                    "$set": {
                        "payment_status": "paid",
                        "session_status": "complete",
                        "updated_at": datetime.now(timezone.utc)
                    }
                }
            )
            
            # Create or update Pro user
            if transaction.get("email"):
                await create_pro_user_from_transaction(transaction, status)
        
        return {
            "session_id": session_id,
            "status": status.status,
            "payment_status": status.payment_status,
            "amount_total": status.amount_total,
            "currency": status.currency
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting checkout status: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la v√©rification du statut")

async def create_pro_user_from_transaction(transaction: dict, status):
    """Create Pro user from successful transaction"""
    try:
        package = PRICING_PACKAGES[transaction["package_id"]]
        
        # Calculate precise expiration date based on subscription type
        now = datetime.now(timezone.utc)
        if package["duration"] == "monthly":
            # Add exactly 1 month (30 days)
            expires = now + timedelta(days=30)
            logger.info(f"Monthly subscription: expires in 30 days ({expires.strftime('%d/%m/%Y %H:%M')})")
        else:  # yearly
            # Add exactly 1 year (365 days)
            expires = now + timedelta(days=365)
            logger.info(f"Yearly subscription: expires in 365 days ({expires.strftime('%d/%m/%Y %H:%M')})")
        
        # Check if user already exists (upgrade/renewal scenario)
        existing_user = await db.pro_users.find_one({"email": transaction["email"]})
        
        if existing_user:
            # User exists - extend subscription from current expiration or now, whichever is later
            current_expires = existing_user.get("subscription_expires")
            if current_expires:
                if isinstance(current_expires, str):
                    current_expires = datetime.fromisoformat(current_expires).replace(tzinfo=timezone.utc)
                elif isinstance(current_expires, datetime) and current_expires.tzinfo is None:
                    current_expires = current_expires.replace(tzinfo=timezone.utc)
                
                # If current subscription is still active, extend from expiration date
                if current_expires > now:
                    if package["duration"] == "monthly":
                        expires = current_expires + timedelta(days=30)
                    else:  # yearly
                        expires = current_expires + timedelta(days=365)
                    logger.info(f"Extending existing subscription from {current_expires.strftime('%d/%m/%Y')} to {expires.strftime('%d/%m/%Y')}")
        
        # Create/Update Pro user
        pro_user = ProUser(
            email=transaction["email"],
            nom=transaction.get("metadata", {}).get("nom") or existing_user.get("nom") if existing_user else None,
            etablissement=transaction.get("metadata", {}).get("etablissement") or existing_user.get("etablissement") if existing_user else None,
            subscription_type=package["duration"],
            subscription_expires=expires,
            last_login=existing_user.get("last_login") if existing_user else None
        )
        
        # Save to database (upsert)
        result = await db.pro_users.update_one(
            {"email": transaction["email"]},
            {"$set": pro_user.dict()},
            upsert=True
        )
        
        action = "updated" if result.matched_count > 0 else "created"
        logger.info(f"Pro user {action}: {transaction['email']} - {package['duration']} subscription expires {expires.strftime('%d/%m/%Y %H:%M')}")
        
        return expires
        
    except Exception as e:
        logger.error(f"Error creating pro user: {e}")
        return None

@api_router.post("/webhook/stripe")
async def stripe_webhook(request: Request):
    """Handle Stripe webhooks"""
    try:
        body = await request.body()
        stripe_signature = request.headers.get("Stripe-Signature")
        
        if not stripe_signature:
            raise HTTPException(status_code=400, detail="Missing Stripe signature")
        
        # Initialize Stripe
        stripe_checkout = StripeCheckout(api_key=stripe_secret_key, webhook_url="")
        
        # Handle webhook
        webhook_response = await stripe_checkout.handle_webhook(body, stripe_signature)
        
        logger.info(f"Webhook received: {webhook_response.event_type} for session {webhook_response.session_id}")
        
        # Process the webhook based on event type
        if webhook_response.event_type == "checkout.session.completed":
            # Find and update transaction
            await db.payment_transactions.update_one(
                {"session_id": webhook_response.session_id},
                {
                    "$set": {
                        "payment_status": webhook_response.payment_status,
                        "session_status": "complete",
                        "updated_at": datetime.now(timezone.utc)
                    }
                }
            )
            
            # Get transaction details for user creation
            transaction = await db.payment_transactions.find_one({"session_id": webhook_response.session_id})
            if transaction and transaction.get("email"):
                # Create Pro user
                await create_pro_user_from_transaction(transaction, webhook_response)
        
        return {"status": "success"}
        
    except Exception as e:
        logger.error(f"Webhook error: {e}")
        raise HTTPException(status_code=400, detail="Webhook processing error")

@api_router.get("/user/status/{email}")
async def get_user_status(email: str):
    """Get user Pro status"""
    try:
        is_pro, user = await check_user_pro_status(email)
        
        if is_pro:
            return {
                "is_pro": True,
                "subscription_type": user.get("subscription_type"),
                "subscription_expires": user.get("subscription_expires"),
                "account_type": "pro"
            }
        else:
            return {
                "is_pro": False,
                "account_type": "guest"
            }
            
    except Exception as e:
        logger.error(f"Error getting user status: {e}")
        return {"is_pro": False, "account_type": "guest"}

@api_router.get("/documents")
@log_execution_time("get_documents")
async def get_documents(guest_id: str = None):
    """Get user documents"""
    logger = get_logger()
    user_type = "guest" if guest_id else "unknown"
    
    logger.info(
        "Starting document retrieval",
        module_name="documents",
        func_name="get_documents",
        user_type=user_type,
        guest_id=guest_id[:8] + "..." if guest_id and len(guest_id) > 8 else guest_id
    )
    
    try:
        if guest_id:
            # Get documents for guest user
            documents = await db.documents.find({"guest_id": guest_id}).sort("created_at", -1).limit(20).to_list(length=20)
        else:
            return {"documents": []}
        
        for doc in documents:
            if isinstance(doc.get('created_at'), str):
                doc['created_at'] = datetime.fromisoformat(doc['created_at'])
            
            # Apply professional content processing to ensure consistency
            # Process all content systematically to handle both old and new documents
            if 'exercises' in doc:
                for exercise in doc['exercises']:
                    if 'enonce' in exercise and exercise['enonce']:
                        exercise['enonce'] = process_exercise_content(exercise['enonce'])
                    
                    # schema_img is now generated during exercise creation, no need to process again
                    if exercise.get('schema_img'):
                        logger.debug(
                            "Schema image already present from generation",
                            module_name="documents",
                            func_name="check_schemas",
                            doc_id=str(doc.get('id', 'unknown'))[:8],
                            has_schema_img=bool(exercise.get('schema_img'))
                        )

                    # Process solution if it exists
                    if exercise.get('solution'):
                        if exercise['solution'].get('resultat'):
                            exercise['solution']['resultat'] = process_exercise_content(exercise['solution']['resultat'])
                                
                        if exercise['solution'].get('etapes') and isinstance(exercise['solution']['etapes'], list):
                            exercise['solution']['etapes'] = [
                                process_exercise_content(step) for step in exercise['solution']['etapes']
                            ]
        
        # Clean up MongoDB-specific fields that can't be JSON serialized
        for doc in documents:
            # Remove MongoDB ObjectId fields that cause serialization issues
            if '_id' in doc:
                del doc['_id']
        
        # Return raw documents to preserve dynamic fields like schema_img
        # Don't use Pydantic models here as they filter out dynamic fields
        return {"documents": documents}
        
    except Exception as e:
        logger.error(f"Error getting documents: {e}")
        return {"documents": []}

@api_router.post("/documents/{document_id}/vary/{exercise_index}")
async def vary_exercise(document_id: str, exercise_index: int):
    """Generate a variation of a specific exercise"""
    try:
        # Find the document
        doc = await db.documents.find_one({"id": document_id})
        if not doc:
            raise HTTPException(status_code=404, detail="Document non trouv√©")
        
        if exercise_index >= len(doc.get("exercises", [])):
            raise HTTPException(status_code=400, detail="Index d'exercice invalide")
        
        # Generate a new variation
        exercises = await generate_exercises_with_ai(
            doc["matiere"],
            doc["niveau"],
            doc["chapitre"],
            doc["type_doc"],
            doc["difficulte"],
            1  # Just one exercise
        )
        
        if exercises:
            # Update the specific exercise
            # Convert Exercise object to dict for MongoDB storage
            exercise_dict = exercises[0].dict() if hasattr(exercises[0], 'dict') else exercises[0]
            doc["exercises"][exercise_index] = exercise_dict
            await db.documents.update_one(
                {"id": document_id},
                {"$set": {"exercises": doc["exercises"]}}
            )
            
            # Return the exercise as dict for JSON serialization
            return {"exercise": exercise_dict}
        
        raise HTTPException(status_code=500, detail="Impossible de g√©n√©rer une variation")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error varying exercise: {e}")
        raise HTTPException(status_code=500, detail="Erreur lors de la g√©n√©ration de la variation")

# Include the router in the main app
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=os.environ.get('CORS_ORIGINS', '*').split(','),
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()